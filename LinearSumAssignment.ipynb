{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is going to explore linear sum assignment. This is a problem that comes up in many different contexts.  For example, you might want to assign workers to tasks, or you might want to assign students to projects.  In this notebook, we'll look at a few different ways to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "TestTensor=torch.rand((300,20))\n",
    "\n",
    "plt.imshow(TestTensor.pow(5),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TruthIndices=linear_sum_assignment(TestTensor.numpy(), maximize=True)\n",
    "\n",
    "plt.imshow(TestTensor)\n",
    "plt.scatter(TruthIndices[1],TruthIndices[0],c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearSumAssignmentLoss(TruthIndices, PredictedIndices):\n",
    "    return torch.sum(torch.pow(TruthIndices-PredictedIndices,2))\n",
    "\n",
    "\n",
    "###\n",
    "'''\n",
    "Linear sum assignment stages:\n",
    "Step 1: Sort the tensor by the columns, max value at the top\n",
    "#Step 2 (Optional) crop max values down to a square\n",
    "Step 3: take top 2 rows and find the biggest delta in the vertical direction and select that Value\n",
    "step 4: mark out everything on that row and column as not selectable \n",
    "'''\n",
    "\n",
    "\n",
    "@torch.jit.script_if_tracing\n",
    "def MyLinearSumAssignment(TruthTensor, maximize=True,lookahead=2):\n",
    "    '''\n",
    "    If Maximize is False, I'm trying to minimize the costs. \n",
    "    This means that the mask must instead make all the weights far above all the others - 'inf' kind of thing. \n",
    "    '''\n",
    "    #assert truthtensor is 2d and nonzero\n",
    "    assert len(TruthTensor.shape)==2\n",
    "    assert TruthTensor.shape[0]>0 and TruthTensor.shape[1]>0\n",
    "    assert lookahead>0\n",
    "    assert torch.sum(TruthTensor==0)==0\n",
    "\n",
    "    mask=torch.ones(TruthTensor.shape,device=TruthTensor.device)\n",
    "    results=torch.zeros(TruthTensor.shape,device=TruthTensor.device)\n",
    "\n",
    "    finder=torch.argmax if maximize else torch.argmin\n",
    "    replaceval=0 if maximize else float(1e9)\n",
    "\n",
    "    for i in range(min(TruthTensor.shape[-2:])): # number of rows\n",
    "        deltas=torch.diff(torch.topk(torch.clamp(TruthTensor*mask,max=100),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas)) # this is the column to grab,  Note this measures step so its not important to do argmin...\n",
    "        row_index=finder(TruthTensor[:,col_index])\n",
    "        mask[:,col_index]=replaceval #mask out the column\n",
    "        mask[row_index]=replaceval\n",
    "        results[row_index,col_index]=1\n",
    "    return results.nonzero(as_tuple=True) \n",
    "TestTensor=torch.rand((300,20))\n",
    "TestTensor=TestTensor.to(\"cuda\")\n",
    "#time this \n",
    "import time \n",
    "\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "X,Y= linear_sum_assignment(TestTensor.cpu().numpy(), maximize=True)\n",
    "X=torch.from_numpy(X).to(\"cuda\")\n",
    "Y=torch.from_numpy(Y).to(\"cuda\")\n",
    "end=time.time()-start\n",
    "print(\"scipy took:\",end)\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    x,y= MyLinearSumAssignment(TestTensor,maximize=True)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "\n",
    "\n",
    "#do intersection over union\n",
    "print(len(set(zip(x,y)).intersection(set(zip(X,Y))))/len(set(zip(x,y)).union(set(zip(X,Y)))))\n",
    "#sum of scores at those indices\n",
    "\n",
    "plt.imshow(TestTensor.cpu().numpy())\n",
    "plt.scatter(y.cpu().numpy(),x.cpu().numpy(),c='r')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(TestTensor.cpu().numpy())\n",
    "plt.scatter(Y.cpu().numpy(),X.cpu().numpy(),c='b')\n",
    "plt.show()\n",
    "\n",
    "print(TestTensor[x,y].sum())\n",
    "\n",
    "print(TestTensor[X,Y].sum())\n",
    "\n",
    "\n",
    "x,y=x.tolist(),y.tolist()\n",
    "X,Y=X.tolist(),Y.tolist()\n",
    "print(set(zip(x,y)))\n",
    "print(set(zip(X,Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    MyLinearSumAssignment(torch.rand((20,80)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched runtimes. The linear sum assignment in use actually runs cpu bound as\n",
    "\n",
    "batched_indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(tgt_sizes.tolist(), -1))]\n",
    "\n",
    "It's actually quite useful to see if theres a way to parallelize this. I'm not sure if there is, but it's worth looking into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original method took: 0.0008642673492431641\n",
      "[(array([ 42,  50, 125, 183, 202]), array([0, 2, 1, 3, 4])), (array([124, 158, 177, 271]), array([0, 2, 1, 3])), (array([ 66, 114, 210]), array([2, 0, 1])), (array([ 36, 192, 214, 294]), array([0, 1, 2, 3])), (array([ 44,  49, 221, 228, 240]), array([1, 3, 2, 4, 0])), (array([ 44,  46, 140, 243]), array([2, 1, 0, 3])), (array([ 67, 140, 181, 246, 247]), array([4, 2, 0, 1, 3]))]\n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           aten::resolve_conj         0.04%       1.000us         0.04%       1.000us       1.000us             1  \n",
      "            aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "       aten::split_with_sizes         0.49%      12.000us         0.57%      14.000us      14.000us             1  \n",
      "             aten::as_strided         0.08%       2.000us         0.08%       2.000us       0.004us           448  \n",
      "                 aten::select        10.15%     249.000us        10.15%     249.000us       1.127us           221  \n",
      "                    aten::cat         1.67%      41.000us         2.28%      56.000us      56.000us             1  \n",
      "                 aten::narrow         3.06%      75.000us         7.38%     181.000us       2.701us            67  \n",
      "                  aten::slice         7.25%     178.000us         7.25%     178.000us       1.402us           127  \n",
      "              aten::ones_like         0.16%       4.000us         0.53%      13.000us      13.000us             1  \n",
      "             aten::empty_like         0.16%       4.000us         0.24%       6.000us       6.000us             1  \n",
      "          aten::empty_strided         0.08%       2.000us         0.08%       2.000us       2.000us             1  \n",
      "                  aten::fill_         2.73%      67.000us         2.77%      68.000us       2.000us            34  \n",
      "                   aten::diag         0.33%       8.000us         1.18%      29.000us      29.000us             1  \n",
      "             aten::diag_embed         0.37%       9.000us         0.86%      21.000us      21.000us             1  \n",
      "                  aten::zeros         0.33%       8.000us         0.37%       9.000us       4.500us             2  \n",
      "                  aten::empty         0.12%       3.000us         0.12%       3.000us       0.081us            37  \n",
      "                  aten::zero_         0.00%       0.000us         0.00%       0.000us       0.000us             2  \n",
      "               aten::diagonal         0.12%       3.000us         0.12%       3.000us       3.000us             1  \n",
      "                  aten::copy_         1.43%      35.000us         1.43%      35.000us       1.129us            31  \n",
      "      aten::repeat_interleave         1.87%      46.000us         6.93%     170.000us      42.500us             4  \n",
      "                 aten::cumsum         0.37%       9.000us         0.37%       9.000us       4.500us             2  \n",
      "                     aten::to         0.00%       0.000us         0.00%       0.000us       0.000us            33  \n",
      "                   aten::item         0.20%       5.000us         0.29%       7.000us       0.033us           214  \n",
      "    aten::_local_scalar_dense         0.08%       2.000us         0.08%       2.000us       0.009us           214  \n",
      "                     aten::ge         0.33%       8.000us         0.33%       8.000us       4.000us             2  \n",
      "                    aten::all         0.37%       9.000us         0.37%       9.000us       4.500us             2  \n",
      "           aten::index_select         0.73%      18.000us         0.81%      20.000us      10.000us             2  \n",
      "                   aten::ones         0.16%       4.000us         0.29%       7.000us       7.000us             1  \n",
      "                    aten::mul         3.91%      96.000us         3.91%      96.000us       3.200us            30  \n",
      "                  aten::clamp         4.07%     100.000us         4.07%     100.000us       3.333us            30  \n",
      "                   aten::topk        29.87%     733.000us        29.87%     733.000us      24.433us            30  \n",
      "                   aten::diff         4.60%     113.000us        13.24%     325.000us      10.833us            30  \n",
      "                    aten::sub         1.83%      45.000us         1.83%      45.000us       1.500us            30  \n",
      "                    aten::abs         4.44%     109.000us         5.75%     141.000us       2.350us            60  \n",
      "                 aten::argmax         5.18%     127.000us         6.68%     164.000us       5.467us            30  \n",
      "                aten::reshape         2.69%      66.000us         2.73%      67.000us       1.117us            60  \n",
      "         aten::_reshape_alias         0.04%       1.000us         0.04%       1.000us       0.017us            60  \n",
      "                 aten::argmin         3.79%      93.000us         3.79%      93.000us       3.100us            30  \n",
      "             aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us            90  \n",
      "             aten::index_put_         1.51%      37.000us         8.11%     199.000us       6.633us            30  \n",
      "       aten::_index_put_impl_         5.38%     132.000us         6.60%     162.000us       5.400us            30  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.454ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-27 11:37:30 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-27 11:37:30 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-27 11:37:30 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-27 11:37:30 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-27 11:37:30 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-27 11:37:30 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  aten::empty         0.03%      17.000us         0.03%      17.000us       0.028us           603  \n",
      "                     aten::to         0.65%     393.000us         4.23%       2.540ms       2.896us           877  \n",
      "             aten::lift_fresh         0.00%       1.000us         0.00%       1.000us       0.333us             3  \n",
      "                aten::detach_         0.01%       5.000us         0.01%       9.000us       3.000us             3  \n",
      "                      detach_         0.01%       4.000us         0.01%       4.000us       1.333us             3  \n",
      "              aten::ones_like         0.97%     581.000us         2.49%       1.493ms       4.977us           300  \n",
      "             aten::empty_like         0.52%     314.000us         1.00%     598.000us       1.993us           300  \n",
      "          aten::empty_strided         0.68%     411.000us         0.68%     411.000us       0.685us           600  \n",
      "                  aten::fill_         0.61%     365.000us         0.61%     365.000us       1.217us           300  \n",
      "                  aten::index        13.75%       8.256ms        15.16%       9.102ms      15.170us           600  \n",
      "             aten::as_strided         0.03%      18.000us         0.03%      18.000us       0.003us          5396  \n",
      "                aten::reshape         3.27%       1.964ms         3.27%       1.966ms       1.311us          1500  \n",
      "         aten::_reshape_alias         0.00%       2.000us         0.00%       2.000us       0.001us          1500  \n",
      "                     aten::gt         3.05%       1.831ms         3.05%       1.831ms       6.103us           300  \n",
      "                  aten::where         5.38%       3.231ms        10.05%       6.037ms      20.123us           300  \n",
      "               aten::_to_copy         1.47%     883.000us         3.85%       2.315ms       7.717us           300  \n",
      "                  aten::copy_         2.33%       1.402ms         2.33%       1.402ms       4.673us           300  \n",
      "             aten::index_put_         1.51%     907.000us        26.42%      15.866ms      26.443us           600  \n",
      "       aten::_index_put_impl_        23.93%      14.373ms        25.07%      15.058ms      25.097us           600  \n",
      "                  aten::slice         5.01%       3.008ms         5.01%       3.009ms       1.256us          2396  \n",
      "                    aten::mul         2.50%       1.501ms         2.50%       1.501ms       5.003us           300  \n",
      "                  aten::clamp         2.26%       1.359ms         2.26%       1.359ms       4.530us           300  \n",
      "                   aten::topk        11.39%       6.841ms        11.39%       6.841ms      22.803us           300  \n",
      "                   aten::diff         1.71%       1.027ms         5.59%       3.354ms      11.180us           300  \n",
      "                 aten::narrow         3.32%       1.995ms         6.18%       3.709ms       2.065us          1796  \n",
      "                    aten::sub         0.93%     560.000us         0.93%     560.000us       1.867us           300  \n",
      "                 aten::select         1.91%       1.149ms         1.93%       1.160ms       1.933us           600  \n",
      "                    aten::abs         1.93%       1.158ms         2.48%       1.488ms       2.480us           600  \n",
      "                 aten::argmax         2.15%       1.289ms         2.88%       1.730ms       5.767us           300  \n",
      "              aten::unsqueeze         1.10%     658.000us         1.10%     658.000us       1.097us           600  \n",
      "                    aten::cat         5.23%       3.141ms         8.72%       5.235ms       8.725us           600  \n",
      "                   aten::item         0.50%     303.000us         0.53%     320.000us       1.067us           300  \n",
      "    aten::_local_scalar_dense         0.03%      17.000us         0.03%      17.000us       0.057us           300  \n",
      "                 aten::argmin         1.80%       1.081ms         1.80%       1.081ms       3.603us           300  \n",
      "                   aten::view         0.01%       8.000us         0.01%       8.000us       8.000us             1  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 60.053ms\n",
      "\n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         aten::unsqueeze         1.98%      16.000us         2.60%      21.000us      21.000us             1  \n",
      "        aten::as_strided         0.99%       8.000us         0.99%       8.000us       0.615us            13  \n",
      "            aten::repeat         6.67%      54.000us        23.36%     189.000us     189.000us             1  \n",
      "            aten::expand         0.49%       4.000us         0.62%       5.000us       2.500us             2  \n",
      "             aten::empty         1.11%       9.000us         1.11%       9.000us       4.500us             2  \n",
      "             aten::alias         0.25%       2.000us         0.25%       2.000us       2.000us             1  \n",
      "            aten::unfold         0.49%       4.000us         0.74%       6.000us       2.000us             3  \n",
      "         aten::expand_as         0.12%       1.000us         0.37%       3.000us       3.000us             1  \n",
      "             aten::copy_        13.84%     112.000us        13.84%     112.000us     112.000us             1  \n",
      "             aten::clamp         6.92%      56.000us         6.92%      56.000us      56.000us             1  \n",
      "                aten::to         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "              aten::topk        53.40%     432.000us        53.40%     432.000us     432.000us             1  \n",
      "              aten::diff         0.99%       8.000us         4.57%      37.000us      37.000us             1  \n",
      "            aten::narrow         1.11%       9.000us         1.85%      15.000us       7.500us             2  \n",
      "             aten::slice         0.99%       8.000us         0.99%       8.000us       2.667us             3  \n",
      "               aten::sub         1.73%      14.000us         1.73%      14.000us      14.000us             1  \n",
      "          aten::diagonal         0.87%       7.000us         0.87%       7.000us       3.500us             2  \n",
      "               aten::abs         1.61%      13.000us         2.47%      20.000us      10.000us             2  \n",
      "            aten::argmax         2.10%      17.000us         2.10%      17.000us      17.000us             1  \n",
      "             aten::index         3.71%      30.000us         4.33%      35.000us      35.000us             1  \n",
      "           aten::reshape         0.62%       5.000us         0.62%       5.000us       5.000us             1  \n",
      "    aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 809.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-27 11:37:31 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-27 11:37:31 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-27 11:37:31 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "def original_method(C: torch.Tensor,sizes: torch.Tensor):\n",
    "    return [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes.tolist(), -1))]\n",
    "\n",
    "##I want to know if theres optimizations in this if I rewrite it to do this at each step\n",
    "@torch.no_grad()\n",
    "def lookup_sizes(sizes:torch.Tensor):\n",
    "    mask=torch.zeros((sizes.sum(),sizes.sum()),device=sizes.device)\n",
    "    start=0\n",
    "    for i in range(len(sizes)):\n",
    "        mask[start:start+sizes[i],start:start+sizes[i]]=1\n",
    "        start+=sizes[i]\n",
    "    plt.imshow(mask)\n",
    "    return mask.bool()\n",
    "\n",
    "@torch.no_grad()\n",
    "def lookup_sizes_vfast(sizes:torch.Tensor):\n",
    "    return torch.diag(torch.ones_like(sizes)).repeat_interleave(sizes,dim=0).repeat_interleave(sizes,dim=1).to(dtype=torch.long,device=sizes.device)\n",
    "\n",
    "@torch.no_grad()\n",
    "#@torch.jit.script\n",
    "def Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    mask=torch.ones(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    finder,replaceval=(torch.argmax,0) if maximize else (torch.argmin,float(1e9))\n",
    "    for _ in range(row_lookups.shape[0]): # number of columns\n",
    "        deltas=torch.diff(torch.topk(torch.clamp(Batched_TruthTensor*mask,max=100),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0])) \n",
    "        row_index=finder(Batched_TruthTensor[:,col_index],dim=0) # BxB\n",
    "        mask[:,col_index]=replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=replaceval\n",
    "        results[row_index,col_index]=1\n",
    "    return results\n",
    "@torch.no_grad()\n",
    "#@torch.jit.script\n",
    "def in_place_Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    #results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    finder,replaceval=(torch.argmax,torch.tensor(0)) if maximize else (torch.argmin,torch.tensor(1e9))\n",
    "    r=torch.tensor([],dtype=torch.long,device=Batched_TruthTensor.device)\n",
    "    c=torch.tensor([],dtype=torch.long,device=Batched_TruthTensor.device)\n",
    "\n",
    "    for i_ in range(Batched_TruthTensor.shape[0]): # number of columns\n",
    "        col_index=torch.argmax(torch.abs(torch.diff(torch.topk(torch.clamp(Batched_TruthTensor*calculate_mask(Batched_TruthTensor,r,c,row_lookups,replaceval=replaceval),max=100),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)[0]))\n",
    "        c=torch.cat([c,col_index.unsqueeze(0)])\n",
    "        r=torch.cat([r,finder(Batched_TruthTensor[:,col_index],dim=0).unsqueeze(0)])\n",
    "    return r,c\n",
    "\n",
    "def no_for_loop_Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    #We're going to first make our cube, which will be BxBxB\n",
    "    #We're going to do this by making a BxB matrix, and then repeating it B times\n",
    "    #results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device).unsqueeze(-1).repeat(1,1,Batched_TruthTensor.shape[-1])\n",
    "    #our first the first set of deltas will be the topk of the first BxB matrix\n",
    "    #finder=(torch.argmax,torch.argmin)[maximize]\n",
    "\n",
    "\n",
    "    #for n in nth slice of cube, I want to find the biggest gap between the max and nth highest value in the column \n",
    "    topk_values,topk_ind=torch.topk(torch.clamp(Batched_TruthTensor.unsqueeze(-1).repeat(1,1,Batched_TruthTensor.shape[-1]),max=100),k=Batched_TruthTensor.shape[-1],dim=0,largest=maximize)\n",
    "    #shape is BxBxB\n",
    "    #for each slice of the cube, I want to find the biggest gap between the max and nth highest value in the column so the shape is BxB\n",
    "    #print(\"values\",topk_values.shape)\n",
    "    #fulldeltas=torch.stack([\n",
    "    #                    torch.diff(topk_values[:,:,n],n=n,dim=0)[0]\n",
    "    #                    for n in range(Batched_TruthTensor.shape[-1])],dim=0)\n",
    "    #print(\"fulldeltas\",fulldeltas.shape) # these are the deltas for each column, from the maximum value to the nth highest value going down the column\n",
    "    #shape is BxB    \n",
    "    deltas=torch.diff(topk_values,n=1,dim=0)\n",
    "    \n",
    "    selection=deltas.diagonal(dim1=1,dim2=2) # this is the difference between the nth highest value and the n+1th highest value in the column\n",
    "\n",
    "    col_index=torch.argmax(torch.abs(selection),dim=0,keepdim=False)\n",
    "    #This should find the column with the biggest gap in the cube and be in the form _,_,B\n",
    "    row_index=topk_ind.diagonal(dim1=1,dim2=2)[:,col_index] # BxB\n",
    "    \n",
    "    #This should find the rows with the biggest gap in the cube and be in the form _,_,B\n",
    "    #print(col_index)\n",
    "    #print(row_index)\n",
    "    #I had expected to end in a one_hot matrix, but I think I'm going to end in a list of indices, and doing a .sum(-1) \n",
    "    return col_index,row_index\n",
    "\n",
    "def calculate_mask(shape:torch.Tensor,ros,cols,row_lookups,replaceval:torch.Tensor=torch.tensor(0)):\n",
    "    tensor=torch.ones_like(shape,dtype=torch.float)\n",
    "    tensor[ros]=torch.where(row_lookups[cols]>0,replaceval,row_lookups[cols])\n",
    "    tensor[:,cols]=replaceval\n",
    "    return tensor\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def lookup_sizes_vfast(sizes:torch.Tensor):\n",
    "    return torch.diag(torch.ones_like(sizes)).repeat_interleave(sizes,dim=0).repeat_interleave(sizes,dim=1).to(dtype=torch.long,device=sizes.device)\n",
    "\n",
    "\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,300,30))\n",
    "sizes=torch.tensor([5,4,3,4,5,4,5],device=Batched_TestTensor.device)\n",
    "start=time.time()\n",
    "outputs=original_method(Batched_TestTensor.clone().cpu(),sizes)\n",
    "\n",
    "x,y=zip(*outputs) #x is output idx, y is tgt idx\n",
    "\n",
    "src=torch.cat([torch.as_tensor(x) for x in x])\n",
    "tgt=torch.cat([torch.as_tensor(y) for y in y])\n",
    "end=time.time()-start\n",
    "print(\"original method took:\",end)\n",
    "print(outputs)\n",
    "fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "row_lookups=lookup_sizes_vfast(sizes)\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "    row_lookups=lookup_sizes_vfast(sizes)\n",
    "    outputs=Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    outputs=in_place_Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    outputs=no_for_loop_Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import reduce,partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Defining the user-defined cubes() function\n",
    "def square(logits):\n",
    "    #a function that takes numpy logits and plots them on an x and y axis\n",
    "    logits=logits.relu()\n",
    "\n",
    "    plt.figure(figsize=(logits.shape[0],logits.shape[1]))\n",
    "    plt.imshow(logits)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def cubes(logits):\n",
    "    # Defining the size of the axes\n",
    "    logits=torch.clamp(logits,min=-1,max=1)\n",
    "    x, y, z = np.indices(logits.shape)\n",
    "    sidex,sidey,sidez=logits.shape\n",
    "    # Defining the length of the sides of the cubes\n",
    "    cube = (x < sidex) & (y < sidey) & (z < sidez)\n",
    "    # Defining the shape of the figure to be a cube\n",
    "    voxelarray = cube\n",
    "    # Defining the colors for the cubes\n",
    "    colors = np.empty((3,*voxelarray.shape), dtype=float)\n",
    "    # Defining the color of the cube\n",
    "    c=np.sqrt(np.sqrt(logits.flatten()).unflatten(0,(sidex,sidey,sidez)).cpu().numpy())\n",
    "    #colors[cube] = c.astype(str)[cube]\n",
    "    colors= np.stack([c,c, c],axis=-1) #c,c,1-c\n",
    "    #print(colors.shape)\n",
    "    # Defining the axes and the figure object\n",
    "    ax = plt.figure(figsize=(9, 9)).add_subplot(projection='3d')\n",
    "    # Plotting the cube in the figure\n",
    "    ax.voxels(voxelarray , facecolors=colors, edgecolor='k')\n",
    "    # Defining the title of the graph\n",
    "    #plt.title(\"Batch MSE loss between random values and perfect case in n=3 dimensions\")\n",
    "    # Displaying the graph\n",
    "    plt.show()\n",
    "\n",
    "def hsquare(logits):\n",
    "    # Defining the size of the axes\n",
    "    logits=torch.clamp(logits,min=-1,max=1)\n",
    "\n",
    "    sidew,sidex,sidey,sidez=logits.shape\n",
    "    x,y = np.indices((sidew*sidex,sidey*sidez))\n",
    "    # Defining the length of the sides of the cubes\n",
    "    square = (x < (sidew*sidex)) & (y < (sidey*sidez))\n",
    "    # Defining the shape of the figure to be a cube\n",
    "    voxelarray = square\n",
    "    # Defining the colors for the cubes\n",
    "    colors = np.empty((*voxelarray.shape,3), dtype=int)\n",
    "    # Defining the color of the cube\n",
    "    #input is shape (B, B, B,B)\n",
    "    #C needs to be (b*b, B*b) \\\n",
    "    c=torch.softmax(logits.flatten(),dim=0).unflatten(0,(sidew*sidex,sidey*sidez)).cpu().numpy()\n",
    "    c=c/np.amax(c)\n",
    "\n",
    "    #c=np.sqrt(np.sqrt(smax(MLoss(sqsqlogits,pfsqsqlogits).flatten()).unflatten(0,(B*B,B*B)).cpu().numpy()))\n",
    "    colors= np.stack([c,c,c],axis=-1)\n",
    "    # Defining the axes and the figure object\n",
    "    ax = plt.imshow(colors[:, :, :])\n",
    "\n",
    "    # Plotting the cube in the figure\n",
    "    # Defining the title of the graph\n",
    "    #plt.title(\"Perfect case logits in n=4 dimensions plotted on a (B^2, B^2) \")\n",
    "    # Displaying the graph\n",
    "    plt.show()\n",
    "# Defining the main() function\n",
    "def hypcubes(side):\n",
    "    # Defining the size of the axes\n",
    "    u,v,w,x, y, z = np.indices((B,B,B,B, B, B))\n",
    "    # Defining the length of the sides of the cubes\n",
    "    cube =  (u < side) & (v < side) & (w < side)& (x < side) & (y < side) & (z < side)\n",
    "    # Defining the shape of the figure to be a cube\n",
    "    voxelarray = cube\n",
    "    # Defining the colors for the cubes\n",
    "    colors = np.empty(voxelarray.shape, dtype=object)\n",
    "    # Defining the color of the cube\n",
    "    c=np.sqrt(np.sqrt(torch.softmax(Blogits.flatten()).unflatten(0,(B,B,B,B,B,B)).cpu().numpy()))*2\n",
    "    colors[cube] = c.astype(str)[cube]\n",
    "    # Defining the axes and the figure object\n",
    "    ax = plt.figure(figsize=(9, 9)).add_subplot(projection='3d')\n",
    "    # Plotting the cube in the figure\n",
    "    ax.voxels(voxelarray , facecolors=colors, edgecolor='k')\n",
    "    # Defining the title of the graph\n",
    "    #plt.title(\"Batch MSE loss between random values and perfect case in n=3 dimensions\")\n",
    "    # Displaying the graph\n",
    "    plt.show()\n",
    "def draw(logits):\n",
    "    # Defining the side of the cube\n",
    "    sides = len(logits.shape) #(subtract to take slices)\n",
    "    # Calling the cubes () function\n",
    "    #cubes(sides)\n",
    "    if sides==2:\n",
    "      square(logits)\n",
    "    if sides==3:\n",
    "      cubes(logits)\n",
    "    if sides==4:\n",
    "      hsquare(logits)\n",
    "    if sides==6:\n",
    "      hypcubes(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 aten::repeat        23.07%       4.224ms        44.34%       8.117ms     122.985us       2.932ms        14.23%       8.380ms     126.970us           0 b           0 b       7.32 Mb           0 b            66  \n",
      "             aten::as_strided         0.08%      14.000us         0.08%      14.000us       0.022us       2.461ms        11.94%       2.461ms       3.950us           0 b           0 b           0 b           0 b           623  \n",
      "                    aten::max         9.78%       1.791ms        10.85%       1.987ms      31.047us       1.992ms         9.67%       2.598ms      40.594us           0 b           0 b     736.00 Kb     736.00 Kb            64  \n",
      "                  aten::copy_         3.05%     558.000us         6.24%       1.142ms       8.785us       1.417ms         6.88%       1.417ms      10.900us           0 b           0 b           0 b           0 b           130  \n",
      "                 aten::unfold         8.36%       1.530ms         8.37%       1.533ms       7.742us       1.390ms         6.75%       2.357ms      11.904us           0 b           0 b           0 b           0 b           198  \n",
      "                 aten::argmax         3.03%     555.000us         3.57%     653.000us      20.406us       1.022ms         4.96%       1.114ms      34.812us           0 b           0 b      16.00 Kb      16.00 Kb            32  \n",
      "                 aten::expand         5.66%       1.037ms         5.69%       1.041ms       7.886us     941.000us         4.57%       1.333ms      10.098us           0 b           0 b           0 b           0 b           132  \n",
      "              aten::unsqueeze         3.11%     569.000us         3.11%     570.000us       8.636us     900.000us         4.37%       1.090ms      16.515us           0 b           0 b           0 b           0 b            66  \n",
      "           aten::masked_fill_         4.14%     758.000us         7.75%       1.418ms      22.156us     858.000us         4.16%       1.469ms      22.953us           0 b           0 b           0 b           0 b            64  \n",
      "                  aten::empty         2.33%     427.000us         2.33%     427.000us       3.163us     751.000us         3.64%     751.000us       5.563us           8 b           8 b      14.59 Mb      14.59 Mb           135  \n",
      "            aten::masked_fill         5.78%       1.059ms        25.73%       4.710ms      73.594us     737.000us         3.58%       4.351ms      67.984us           0 b           0 b       7.27 Mb           0 b            64  \n",
      "                    aten::div         1.15%     210.000us         1.68%     308.000us       9.625us     713.000us         3.46%     713.000us      22.281us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                  aten::clone         5.47%       1.001ms        12.20%       2.233ms      34.891us     688.000us         3.34%       2.145ms      33.516us           0 b           0 b       7.27 Mb           0 b            64  \n",
      "                aten::permute         3.26%     597.000us         3.26%     597.000us       9.328us     543.000us         2.64%     740.000us      11.562us           0 b           0 b           0 b           0 b            64  \n",
      "                    aten::sub         0.99%     181.000us         1.44%     263.000us       8.219us     513.000us         2.49%     513.000us      16.031us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "             aten::empty_like         2.78%     509.000us         3.87%     708.000us      11.062us     455.000us         2.21%     803.000us      12.547us           0 b           0 b       7.27 Mb           0 b            64  \n",
      "              aten::expand_as         2.67%     489.000us         5.49%       1.006ms      15.242us     439.000us         2.13%       1.094ms      16.576us           0 b           0 b           0 b           0 b            66  \n",
      "                    aten::add         1.45%     266.000us         1.99%     365.000us      11.406us     438.000us         2.13%     438.000us      13.688us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                   aten::item         2.53%     464.000us         2.54%     465.000us       7.266us     436.000us         2.12%     611.000us       9.547us           0 b           0 b           0 b           0 b            64  \n",
      "                aten::numpy_T         2.71%     497.000us         5.98%       1.094ms      17.094us     392.000us         1.90%       1.132ms      17.688us           0 b           0 b           0 b           0 b            64  \n",
      "                  aten::alias         0.02%       3.000us         0.02%       3.000us       0.045us     190.000us         0.92%     190.000us       2.879us           0 b           0 b           0 b           0 b            66  \n",
      "    aten::_local_scalar_dense         0.01%       1.000us         0.01%       1.000us       0.016us     175.000us         0.85%     175.000us       2.734us           0 b           0 b           0 b           0 b            64  \n",
      "                  aten::fill_         0.14%      26.000us         0.28%      51.000us      12.750us      67.000us         0.33%      67.000us      16.750us           0 b           0 b           0 b           0 b             4  \n",
      "                 aten::arange         0.18%      33.000us         0.34%      63.000us      31.500us      33.000us         0.16%      70.000us      35.000us           0 b           0 b       1.00 Kb           0 b             2  \n",
      "                  aten::zeros         0.19%      35.000us         0.53%      97.000us      48.500us      27.000us         0.13%     105.000us      52.500us           0 b           0 b       2.00 Kb           0 b             2  \n",
      "         aten::fill_diagonal_         0.18%      33.000us         0.31%      57.000us      28.500us      26.000us         0.13%      63.000us      31.500us           0 b           0 b           0 b           0 b             2  \n",
      "                  aten::zero_         0.10%      19.000us         0.28%      51.000us      25.500us      17.000us         0.08%      59.000us      29.500us           0 b           0 b           0 b           0 b             2  \n",
      "                 aten::select         0.08%      14.000us         0.08%      15.000us      15.000us      13.000us         0.06%      18.000us      18.000us           0 b           0 b           0 b           0 b             1  \n",
      "                aten::detach_         0.08%      15.000us         0.09%      16.000us       8.000us      13.000us         0.06%      22.000us      11.000us           0 b           0 b           0 b           0 b             2  \n",
      "                      detach_         0.01%       1.000us         0.01%       1.000us       0.500us       9.000us         0.04%       9.000us       4.500us           0 b           0 b           0 b           0 b             2  \n",
      "                aten::resize_         0.02%       3.000us         0.02%       3.000us       3.000us       7.000us         0.03%       7.000us       7.000us           0 b           0 b         512 b         512 b             1  \n",
      "                     aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.03%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "             aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.03%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "                     [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us          -8 b          -8 b     -15.70 Mb     -15.70 Mb           451  \n",
      "             cudaLaunchKernel         5.73%       1.049ms         5.73%       1.049ms       3.208us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           327  \n",
      "              cudaMemcpyAsync         1.83%     335.000us         1.83%     335.000us       5.234us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "        cudaDeviceSynchronize         0.03%       5.000us         0.03%       5.000us       5.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 18.308ms\n",
      "Self CUDA time total: 20.607ms\n",
      "\n",
      "func recursive ACC : 17/30\n",
      "score: tensor(268.3737, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          aten::nonzero         9.73%       3.150ms        25.77%       8.343ms     130.359us       5.802ms        16.22%       8.081ms     126.266us           0 b           0 b      34.00 Kb       7.50 Kb            64  \n",
      "                                           aten::select         8.39%       2.715ms         8.39%       2.717ms       8.464us       2.984ms         8.34%       3.883ms      12.097us           0 b           0 b           0 b           0 b           321  \n",
      "                                       aten::as_strided         0.03%       9.000us         0.03%       9.000us       0.009us       2.904ms         8.12%       2.904ms       2.833us           0 b           0 b           0 b           0 b          1025  \n",
      "                                 aten::_index_put_impl_        10.75%       3.481ms        43.26%      14.002ms     218.781us       2.577ms         7.20%      13.419ms     209.672us           0 b           0 b       1.50 Kb     -32.50 Kb            64  \n",
      "                                           aten::repeat        11.04%       3.575ms        21.14%       6.843ms     106.922us       2.301ms         6.43%       7.553ms     118.016us           0 b           0 b     256.00 Kb           0 b            64  \n",
      "                                             aten::topk         4.00%       1.294ms         5.38%       1.741ms      27.203us       2.157ms         6.03%       2.157ms      33.703us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                        aten::unsqueeze         3.28%       1.062ms         3.28%       1.062ms       8.297us       1.838ms         5.14%       2.192ms      17.125us           0 b           0 b           0 b           0 b           128  \n",
      "                                           aten::expand         2.96%     958.000us         2.96%     958.000us       7.484us       1.305ms         3.65%       1.675ms      13.086us           0 b           0 b           0 b           0 b           128  \n",
      "                                         aten::scatter_         2.86%     926.000us         3.50%       1.132ms      17.688us       1.278ms         3.57%       1.450ms      22.656us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::copy_         1.21%     393.000us         1.98%     642.000us      10.031us       1.079ms         3.02%       1.079ms      16.859us           0 b           0 b           0 b           0 b            64  \n",
      "                                          aten::reshape         3.06%     992.000us         3.06%     992.000us       7.750us     945.000us         2.64%       1.302ms      10.172us           0 b           0 b           0 b           0 b           128  \n",
      "                                    aten::empty_strided         0.68%     219.000us         0.68%     219.000us       3.422us     918.000us         2.57%     918.000us      14.344us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                           aten::unfold         3.03%     982.000us         3.04%     984.000us       7.688us     915.000us         2.56%       1.272ms       9.938us           0 b           0 b           0 b           0 b           128  \n",
      "                                                aten::t         1.49%     481.000us         3.12%       1.009ms      15.766us     841.000us         2.35%       1.695ms      26.484us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::slice         2.81%     910.000us         2.81%     910.000us       9.479us     791.000us         2.21%       1.068ms      11.125us           0 b           0 b           0 b           0 b            96  \n",
      "                                       aten::zeros_like         3.01%     974.000us         8.27%       2.676ms      41.812us     692.000us         1.93%       3.073ms      48.016us           0 b           0 b      64.00 Kb           0 b            64  \n",
      "                                        aten::expand_as         1.48%     480.000us         2.95%     954.000us      14.906us     675.000us         1.89%       1.302ms      20.344us           0 b           0 b           0 b           0 b            64  \n",
      "                                        aten::transpose         1.62%     523.000us         1.63%     528.000us       8.250us     652.000us         1.82%     854.000us      13.344us           0 b           0 b           0 b           0 b            64  \n",
      "                                           aten::argmax         1.76%     571.000us         2.07%     670.000us      20.938us     579.000us         1.62%     671.000us      20.969us           0 b           0 b      16.00 Kb      16.00 Kb            32  \n",
      "                                            aten::fill_         0.66%     214.000us         1.26%     408.000us       6.375us     558.000us         1.56%     558.000us       8.719us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::index_put_         1.80%     582.000us        45.05%      14.584ms     227.875us     469.000us         1.31%      13.888ms     217.000us           0 b           0 b           0 b      -1.50 Kb            64  \n",
      "                                            aten::zero_         1.76%     569.000us         3.02%     977.000us      15.266us     465.000us         1.30%       1.023ms      15.984us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::empty_like         1.56%     506.000us         2.24%     725.000us      11.328us     440.000us         1.23%       1.358ms      21.219us           0 b           0 b      64.00 Kb           0 b            64  \n",
      "                                            aten::empty         0.66%     214.000us         0.66%     214.000us       3.194us     386.000us         1.08%     386.000us       5.761us           8 b           8 b     256.00 Kb     256.00 Kb            67  \n",
      "                                              aten::add         0.74%     238.000us         1.04%     338.000us      10.562us     367.000us         1.03%     367.000us      11.469us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us     357.000us         1.00%     357.000us       2.789us           0 b           0 b           0 b           0 b           128  \n",
      "                                          aten::resize_         0.43%     138.000us         0.43%     138.000us       2.123us     355.000us         0.99%     355.000us       5.462us           0 b           0 b      27.00 Kb      27.00 Kb            65  \n",
      "                                              aten::div         0.72%     234.000us         1.03%     333.000us      10.406us     341.000us         0.95%     341.000us      10.656us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                              aten::sub         0.59%     190.000us         0.86%     278.000us       8.688us     313.000us         0.87%     313.000us       9.781us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                             aten::set_         1.68%     544.000us         1.68%     544.000us       8.500us     234.000us         0.65%     234.000us       3.656us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::alias         0.00%       0.000us         0.00%       0.000us       0.000us     185.000us         0.52%     185.000us       2.891us           0 b           0 b           0 b           0 b            64  \n",
      "                                           aten::arange         0.10%      31.000us         0.18%      58.000us      29.000us      32.000us         0.09%      65.000us      32.500us           0 b           0 b       1.00 Kb           0 b             2  \n",
      "                                          aten::detach_         0.05%      17.000us         0.06%      18.000us       9.000us      18.000us         0.05%      25.000us      12.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.02%       7.000us       3.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                                detach_         0.00%       1.000us         0.00%       1.000us       0.500us       7.000us         0.02%       7.000us       3.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.02%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us          -8 b          -8 b    -784.50 Kb    -784.50 Kb           451  \n",
      "                                       cudaLaunchKernel         6.99%       2.264ms         6.99%       2.264ms       2.944us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           769  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.003us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           320  \n",
      "                                  cudaFuncGetAttributes         0.28%      90.000us         0.28%      90.000us       1.406us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.01%       2.000us         0.01%       2.000us       0.004us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           512  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           384  \n",
      "                                        cudaMemcpyAsync         8.55%       2.769ms         8.55%       2.769ms      43.266us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "                                  cudaStreamSynchronize         0.21%      67.000us         0.21%      67.000us       1.047us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "                                  cudaDeviceSynchronize         0.01%       4.000us         0.01%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 32.370ms\n",
      "Self CUDA time total: 35.773ms\n",
      "\n",
      "func recursive v2 \n",
      " ACC : 16/30\n",
      "score: tensor(267.2455, device='cuda:0')\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::argmax         9.40%       1.539ms        11.19%       1.831ms      19.073us       1.876ms         9.94%       2.158ms      22.479us           0 b           0 b      48.00 Kb      48.00 Kb            96  \n",
      "                                             aten::topk         7.09%       1.160ms         9.57%       1.566ms      24.469us       1.730ms         9.16%       1.730ms      27.031us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                              aten::max         3.93%     644.000us         5.19%     850.000us      13.281us       1.391ms         7.37%       1.391ms      21.734us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                              aten::sub         3.92%     642.000us         5.55%     908.000us       9.458us       1.359ms         7.20%       1.359ms      14.156us           0 b           0 b     160.00 Kb     160.00 Kb            96  \n",
      "                                       aten::as_strided         0.07%      11.000us         0.07%      11.000us       0.029us       1.110ms         5.88%       1.110ms       2.883us           0 b           0 b           0 b           0 b           385  \n",
      "                                            aten::zero_         3.44%     563.000us         5.79%     948.000us      14.812us       1.065ms         5.64%       1.600ms      25.000us           0 b           0 b           0 b           0 b            64  \n",
      "                                        aten::unsqueeze         3.21%     526.000us         3.21%     526.000us       8.219us       1.025ms         5.43%       1.205ms      18.828us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::add         3.64%     596.000us         5.16%     845.000us       8.802us       1.023ms         5.42%       1.023ms      10.656us           0 b           0 b     384.00 Kb     384.00 Kb            96  \n",
      "                                            aten::slice         6.69%       1.095ms         6.73%       1.102ms       8.609us       1.005ms         5.32%       1.387ms      10.836us           0 b           0 b           0 b           0 b           128  \n",
      "                                             aten::diff         9.06%       1.483ms        25.80%       4.223ms      65.984us     980.000us         5.19%       4.024ms      62.875us           0 b           0 b      32.00 Kb           0 b            64  \n",
      "                                          aten::one_hot         9.11%       1.491ms        31.15%       5.099ms      79.672us     913.000us         4.84%       5.838ms      91.219us           0 b           0 b     480.00 Kb           0 b            64  \n",
      "                                         aten::scatter_         4.87%     798.000us         6.05%     991.000us      15.484us     905.000us         4.79%       1.078ms      16.844us           0 b           0 b           0 b           0 b            64  \n",
      "                                           aten::narrow         6.05%     990.000us        12.78%       2.092ms      16.344us     879.000us         4.66%       2.266ms      17.703us           0 b           0 b           0 b           0 b           128  \n",
      "                                              aten::mul         2.85%     466.000us         4.03%     660.000us      10.312us     823.000us         4.36%     823.000us      12.859us           0 b           0 b     256.00 Kb     256.00 Kb            64  \n",
      "                                              aten::div         1.23%     201.000us         1.81%     297.000us       9.281us     730.000us         3.87%     730.000us      22.812us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                            aten::zeros         5.81%     951.000us        12.77%       2.091ms      32.672us     706.000us         3.74%       2.642ms      41.281us           0 b           0 b     480.00 Kb           0 b            64  \n",
      "                                            aten::fill_         1.22%     199.000us         2.35%     385.000us       6.016us     535.000us         2.83%     535.000us       8.359us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::empty         1.19%     194.000us         1.19%     194.000us       2.985us     337.000us         1.79%     337.000us       5.185us           0 b           0 b     480.00 Kb     480.00 Kb            65  \n",
      "                                          aten::permute         1.65%     270.000us         1.65%     270.000us       8.438us     248.000us         1.31%     334.000us      10.438us           0 b           0 b           0 b           0 b            32  \n",
      "                                          aten::numpy_T         1.41%     230.000us         3.05%     500.000us      15.625us     201.000us         1.06%     535.000us      16.719us           0 b           0 b           0 b           0 b            32  \n",
      "                                           aten::select         0.15%      24.000us         0.16%      27.000us      27.000us      24.000us         0.13%      31.000us      31.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                           aten::arange         0.18%      30.000us         0.36%      59.000us      29.500us      11.000us         0.06%      19.000us       9.500us           0 b           0 b       1.00 Kb           0 b             2  \n",
      "                                          aten::resize_         0.02%       3.000us         0.02%       3.000us       3.000us       1.000us         0.01%       1.000us       1.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                       cudaLaunchKernel        12.33%       2.018ms        12.33%       2.018ms       2.862us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           705  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      -1.55 Mb      -1.55 Mb           769  \n",
      "                                 cudaDeviceGetAttribute         0.01%       1.000us         0.01%       1.000us       0.004us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           256  \n",
      "                                  cudaFuncGetAttributes         0.42%      69.000us         0.42%      69.000us       1.078us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.02%       3.000us         0.02%       3.000us       0.006us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           512  \n",
      "                                  cudaDeviceSynchronize         1.06%     173.000us         1.06%     173.000us     173.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 16.370ms\n",
      "Self CUDA time total: 18.877ms\n",
      "\n",
      "func recursive v3 \n",
      " ACC : 17/30\n",
      "score: tensor(268.3737, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "def no_for_loop_triu_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "    remove=torch.ones_like(rewards,dtype=torch.bool).triu().unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights,dim=0).values\n",
    "    Locations=comb_fn(rewards,Costs)\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "def no_for_loop_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights,dim=0).values\n",
    "    #plt.show(plt.imshow(Costs.cpu().numpy()))\n",
    "    \n",
    "    Locations=comb_fn(rewards,Costs)\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "def no_for_loop_v2_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "\n",
    "    Costs=next_highest_fn(weights1,dim=1).values\n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "def no_for_loop_v2_triu_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "   \n",
    "    remove=torch.ones_like(rewards,dtype=torch.bool).tril().unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights1,dim=1).values \n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "def no_for_loop_v3_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "\n",
    "    Costs=next_highest_fn(weights1,dim=1).values\n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "def no_for_loop_v3_triu_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "   \n",
    "    remove=torch.ones_like(rewards,dtype=torch.bool).tril().unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights1,dim=1).values \n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "\n",
    "def reduceLinearSumAssignment(rewards:torch.Tensor,cost_neg:torch.Tensor,next_highest_fn: Callable,remove):\n",
    "    removehw,removehwT=remove\n",
    "    # rewards is HW, weights is  B(H) H W \n",
    "    weights=rewards.unsqueeze(0).repeat(*tuple([rewards.shape[0]]+ [1]*len(rewards.shape)))\n",
    "    #rewards is shape hw, weights is shape h w w\n",
    "    weights=weights.masked_fill(removehw,cost_neg)#.permute(1,2,0)\n",
    "    #draw(weights.cpu())\n",
    "    Costs=next_highest_fn(weights,dim=1).values #should not be 0  \n",
    "    #draw(Costs.cpu())\n",
    "    #print(Costs.shape)\n",
    "    weights2=rewards.T.unsqueeze(0).repeat(*tuple([rewards.shape[1]]+ [1]*len(rewards.shape)))\n",
    "\n",
    "    weights2=weights2.masked_fill(removehwT,cost_neg)#.permute(1,2,0)\n",
    "    Costs2=next_highest_fn(weights2,dim=1).values #should not be 0\n",
    "    #d#raw(Costs2.cpu())\n",
    "    #print(Costs2.shape)\n",
    "    Cost_total= torch.add(Costs,Costs2.T)\n",
    "    return Cost_total\n",
    "\n",
    "def reduceLinearSumAssignment_vm(rewards:torch.Tensor,cost_neg:torch.Tensor,next_highest_fn: Callable,remove:torch.Tensor):\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "    \n",
    "    Costs=next_highest_fn(weights1,dim=1).values #should not be 0  \n",
    "    Costs2=next_highest_fn(weights2,dim=0).values #should not be 0\n",
    "\n",
    "    #Cost_total=Costs+Costs2 # max,min or plus? min max seem to be worse than plus\n",
    "    Cost_total= torch.add(Costs,Costs2)\n",
    "    \n",
    "    return Cost_total\n",
    "def reduceLinearSumAssignment_v2(rewards:torch.Tensor,maximize=False):\n",
    "    Topv,topi=rewards.topk(k=2,dim=1,largest=maximize)\n",
    "    costs=Topv[:,0].unsqueeze(1).repeat(1,rewards.shape[-1])\n",
    "    #print(costs.shape)\n",
    "    one_hot=torch.zeros_like(rewards, dtype=torch.bool).scatter_(1,topi[:,0].unsqueeze(1),1)\n",
    "    #draw(one_hot.to(dtype=torch.float,device=\"cpu\"))\n",
    "    costs[one_hot]=Topv[:,1]\n",
    "    #draw(costs.cpu())\n",
    "    topv2,topi2=rewards.topk(k=2,dim=0,largest=maximize)\n",
    "    costs2=topv2[0].unsqueeze(0).repeat(rewards.shape[0],1)\n",
    "    one_hot2 = torch.zeros_like(rewards, dtype=torch.bool).scatter_(0, topi2[0].unsqueeze(0), 1)\n",
    "    costs2[one_hot2]=topv2[1]\n",
    "    #draw(costs2.cpu())\n",
    "    Cost_total= costs2+costs\n",
    "    #draw(Cost_total.cpu())\n",
    "\n",
    "    return Cost_total\n",
    "\n",
    "\n",
    "def reduceLinearSumAssignment_v3(rewards:torch.Tensor,maximize=False):\n",
    "\n",
    "    #30,32\n",
    "    TotalCosts= torch.max(rewards,dim=1,keepdim=True).values + torch.max(rewards,dim=0,keepdim=True).values\n",
    "    #30,32\n",
    "    diffs= torch.diff(rewards.topk(k=2,dim=1,largest=maximize).values,dim=1)\n",
    "    #30,1\n",
    "    diffs2= torch.diff(rewards.topk(k=2,dim=0,largest=maximize).values,dim=0)\n",
    "    #1,32\n",
    "    one_hot=torch.nn.functional.one_hot(torch.argmax(rewards,dim=1),num_classes=rewards.shape[1])\n",
    "    #30,32\n",
    "    one_hot=one_hot*diffs\n",
    "    #30,32\n",
    "    one_hot2=torch.nn.functional.one_hot(torch.argmax(rewards,dim=0),num_classes=rewards.shape[0])\n",
    "    #32,30\n",
    "\n",
    "    one_hot2=one_hot2.T * diffs2\n",
    "    deltas=one_hot+one_hot2\n",
    "    totalCosts=TotalCosts+deltas\n",
    "    return totalCosts\n",
    "\n",
    "\n",
    "def reduceLinearSumAssignment_v4(rewards:torch.Tensor,maximize=False):\n",
    "\n",
    "    #30,32\n",
    "    TotalCosts= torch.max(rewards,dim=1,keepdim=True).values + torch.max(rewards,dim=0,keepdim=True).values\n",
    "    #30,32\n",
    "    #diffs= torch.diff(rewards.topk(k=2,dim=1,largest=maximize).values,dim=1)\n",
    "    #30,1\n",
    "    diffs2= torch.diff(rewards.topk(k=2,dim=0,largest=maximize).values,dim=0)\n",
    "    #1,32\n",
    "    #one_hot=torch.nn.functional.one_hot(torch.argmax(rewards,dim=1),num_classes=rewards.shape[1])\n",
    "    #30,32\n",
    "    #one_hot=one_hot*diffs\n",
    "    #30,32\n",
    "    one_hot2=torch.nn.functional.one_hot(torch.argmax(rewards,dim=0),num_classes=rewards.shape[0])\n",
    "    #32,30\n",
    "\n",
    "    one_hot2=one_hot2.T * diffs2\n",
    "    #deltas=one_hot+one_hot2\n",
    "    totalCosts=TotalCosts+one_hot2#deltas\n",
    "    return totalCosts\n",
    "\n",
    "def recursiveLinearSumAssignment(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((torch.tensor(float('inf')),torch.min,torch.add,torch.argmin),(torch.tensor(float('-inf')),torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #we need to make a mask that holds the diagonal of a H x H matrix repeated B times, and then one with the diagonal of a BxB matrix repeated H times\n",
    "\n",
    "    removeHHB=torch.zeros((rewards.shape[0],rewards.shape[0]),dtype=torch.bool,device=rewards.device).fill_diagonal_(1).unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape) + [rewards.shape[1]]))\n",
    "    removeBBH=torch.zeros((rewards.shape[1],rewards.shape[1]),dtype=torch.bool,device=rewards.device).fill_diagonal_(1).unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[0]]))\n",
    "    y_values=[]\n",
    "    #rewards=rewards-  (rewards.min())\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost=reduceLinearSumAssignment(rewards,cost_neg,next_highest_fn,(removeHHB,removeBBH))\n",
    "        rewards=rewards - cost/factor\n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index, y_values\n",
    "\n",
    "def recursiveLinearSumAssignment_v2(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((torch.tensor(float('inf')),torch.min,torch.add,torch.argmin),(torch.tensor(float('-inf')),torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    # remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost2=reduceLinearSumAssignment_v2(rewards,maximize=maximize)\n",
    "        rewards=rewards- (cost2/factor)# can remove\n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #return torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index, y_values\n",
    "\n",
    "def recursiveLinearSumAssignment_v3(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    final_fn=torch.argmax if maximize else torch.argmin\n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost=reduceLinearSumAssignment_v3(rewards,maximize=maximize)\n",
    "        rewards=rewards-(cost/factor)# can remove\n",
    "        #draw(rewards.cpu())\n",
    "        #? why is this suggested??? rewards,_,_=torch.svd(rewards)\n",
    "        #rewards=rewards ** (rewards-cost/factor) #times here makes it very spiky! \n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index,y_values\n",
    "\n",
    "def recursiveLinearSumAssignment_v4(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    final_fn=torch.argmax if maximize else torch.argmin\n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost=reduceLinearSumAssignment_v3(rewards,maximize=maximize)\n",
    "        rewards=rewards-(cost/factor)# can remove\n",
    "        #draw(rewards.cpu())\n",
    "        #? why is this suggested??? rewards,_,_=torch.svd(rewards)\n",
    "        #rewards=rewards ** (rewards-cost/factor) #times here makes it very spiky! \n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index,y_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def recursiveLinearSumAssignment_reductionComparison(rewards:torch.Tensor,maximize=False,factor=0.1):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((torch.tensor(float('inf')),torch.min,torch.add,torch.argmin),(torch.tensor(float('-inf')),torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "\n",
    "        cost=reduceLinearSumAssignment(rewards,cost_neg,next_highest_fn,remove)\n",
    "        cost2=reduceLinearSumAssignment_v2(rewards,maximize=maximize)\n",
    "        cost3=reduceLinearSumAssignment_v3(rewards,maximize=maximize)\n",
    "        draw(cost3.cpu())\n",
    "        draw(cost2.cpu())\n",
    "        draw(cost.cpu())\n",
    "        print(\"Cost- v2\",torch.mean(torch.abs(cost-cost2)))\n",
    "        print(\"cost- v3\",torch.mean(torch.abs(cost-cost3)))\n",
    "        print(\"2 v 3\",torch.mean(torch.abs(cost2-cost3)))\n",
    "        rewards=rewards- (cost2/factor)# can remove\n",
    "    \n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index, y_values\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#try linear sum assignment\n",
    "import time\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,30,32)).cuda()\n",
    "Batched_TestTensor=Batched_TestTensor*10\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, record_shapes=True, with_flops=True, profile_memory=True) as prof: \n",
    "    X,Y=linear_sum_assignment(Batched_TestTensor[0].cpu().numpy(), maximize=True)\n",
    "    \n",
    "# print(\"scipy took:\")\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "# print(\"score:\",Batched_TestTensor[0][X,Y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x,y,_=recursiveLinearSumAssignment(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} ACC : {}/{}\".format(\"recursive\",torch.sum(y.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x,y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x1,y1,_=recursiveLinearSumAssignment_v2(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v2\",torch.sum(y1.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x1,y1].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x2,y2,_=recursiveLinearSumAssignment_v3(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v3\",torch.sum(y2.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x2,y2].sum())\n",
    "\n",
    "\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x2,y2,_=recursiveLinearSumAssignment_v4(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v3\",torch.sum(y2.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x2,y2].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#try linear sum assignment\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m Batched_TestTensor\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mrand((\u001b[39m8\u001b[39m,\u001b[39m30\u001b[39m,\u001b[39m30\u001b[39m))\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m Batched_TestTensor\u001b[39m=\u001b[39mBatched_TestTensor\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile() \u001b[39mas\u001b[39;00m prof:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#try linear sum assignment\n",
    "import time\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,30,30)).cuda()\n",
    "Batched_TestTensor=Batched_TestTensor*10\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    X,Y=linear_sum_assignment(Batched_TestTensor[0].cpu().numpy(), maximize=True)\n",
    "    \n",
    "print(\"scipy took:\")\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"score:\",Batched_TestTensor[0][X,Y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    x,y,_=recursiveLinearSumAssignment(Batched_TestTensor[0],maximize=True)\n",
    "draw((torch.stack(_,dim=0).cpu()==torch.as_tensor(Y)).int().to(dtype=torch.float,device=\"cpu\"))\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} ACC : {}/{}\".format(\"recursive\",torch.sum(y.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x,y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof: \n",
    "    x1,y1,_=recursiveLinearSumAssignment_v2(Batched_TestTensor[0],maximize=True)\n",
    "draw((torch.stack(_,dim=0).cpu()==torch.as_tensor(Y)).int().to(dtype=torch.float,device=\"cpu\"))\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v2\",torch.sum(y1.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x1,y1].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof: \n",
    "    x1,y1,_=recursiveLinearSumAssignment_v3(Batched_TestTensor[0],maximize=True)\n",
    "draw((torch.stack(_,dim=0).cpu()==torch.as_tensor(Y)).int().to(dtype=torch.float,device=\"cpu\"))\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v3\",torch.sum(y1.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x1,y1].sum())\n",
    "for factor in np.arange(0.2,3,0.1):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.abs(torch.rand((30,30)))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "  \n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "x_axis=\"Number of times the steps\"\n",
    "y_axis=\"Fraction of correct assignments\"\n",
    "plt.xlabel(x_axis)\n",
    "plt.ylabel(y_axis)\n",
    "\n",
    "title=\"A Graph showing mean accuracy based on cost matrix\"\n",
    "plt.title(title)  \n",
    "plt.show()\n",
    "for factor in np.arange(0.2,3,0.2):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.rand((30,30))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment_v2(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "    title=\"A Graph showing mean accuracy based on multiplying by costs, factor:{}\".format(\"0.2 - 3 in steps of 0.1\")\n",
    "    plt.title(title)\n",
    "    #x axis is the number of times the algorithm was run\n",
    "    #y axis is the accuracy\n",
    "    x_axis=\"Number of times the steps\"\n",
    "    y_axis=\"Fraction of correct assignments\"\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "\n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for factor in np.arange(0.2,3,0.1):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.rand((30,30))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment_v3(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "    title=\"A Graph showing mean accuracy based on multiplying by costs, factor:{}\".format(\"0.2 - 3 in steps of 0.1\")\n",
    "    plt.title(title)\n",
    "    #x axis is the number of times the algorithm was run\n",
    "    #y axis is the accuracy\n",
    "    x_axis=\"Number of times the steps\"\n",
    "    y_axis=\"Fraction of correct assignments\"\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "\n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for factor in np.arange(0.2,3,0.1):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.rand((30,30))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment_v4(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "    title=\"A Graph showing mean accuracy based on multiplying by costs, factor:{}\".format(\"0.2 - 3 in steps of 0.1\")\n",
    "    plt.title(title)\n",
    "    #x axis is the number of times the algorithm was run\n",
    "    #y axis is the accuracy\n",
    "    x_axis=\"Number of times the steps\"\n",
    "    y_axis=\"Fraction of correct assignments\"\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "\n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#try linear sum assignment\n",
    "import time\n",
    "start=time.time()\n",
    "X,Y=linear_sum_assignment(Batched_TestTensor[0].cpu().numpy(), maximize=False)\n",
    "end=time.time()-start\n",
    "print(\"scipy took:\",end)\n",
    "print(\"score:\",Batched_TestTensor[0][X,Y].sum())\n",
    "trial_functions=[no_for_loop_MyLinearSumAssignment,\n",
    "                 no_for_loop_triu_MyLinearSumAssignment,\n",
    "                 no_for_loop_v2_MyLinearSumAssignment,\n",
    "                 no_for_loop_v2_triu_MyLinearSumAssignment,\n",
    "                 no_for_loop_v3_MyLinearSumAssignment,\n",
    "                 no_for_loop_v3_triu_MyLinearSumAssignment]\n",
    "for func in trial_functions:\n",
    "    warmup,_=func(Batched_TestTensor[0])\n",
    "    start=time.time()\n",
    "    x,y=func(Batched_TestTensor[0],maximize=False)\n",
    "    end=time.time()-start\n",
    "    print(\"func {} \\n TOOK {}, \\n ACC : {}/{}\".format(func,end,torch.sum(y==torch.as_tensor(Y)),len(Y)))\n",
    "    print(\"score:\",Batched_TestTensor[0][x,y].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to construct some nn.modules instead of this heavy set of calls and for loops\n",
    "for the Batch_Linear sum assignment method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::resolve_conj         0.01%       1.000us         0.01%       1.000us       1.000us             1  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.40%      33.000us         9.79%     811.000us      12.477us            65  \n",
      "                                         aten::_to_copy         1.15%      95.000us         9.40%     778.000us      25.097us            31  \n",
      "                                    aten::empty_strided         1.16%      96.000us         1.16%      96.000us       3.000us            32  \n",
      "                                            aten::copy_         6.36%     527.000us        10.58%     876.000us      14.129us            62  \n",
      "                                        cudaMemcpyAsync        16.61%       1.375ms        16.61%       1.375ms       5.612us           245  \n",
      "                                  cudaStreamSynchronize         3.61%     299.000us         3.61%     299.000us       1.220us           245  \n",
      "                                 aten::split_with_sizes         0.17%      14.000us         0.18%      15.000us      15.000us             1  \n",
      "                                       aten::as_strided         0.08%       7.000us         0.08%       7.000us       0.016us           439  \n",
      "                                           aten::select         4.24%     351.000us         4.31%     357.000us       1.630us           219  \n",
      "                                              aten::cat         0.21%      17.000us         0.33%      27.000us      27.000us             1  \n",
      "                                       cudaLaunchKernel        12.28%       1.017ms        12.28%       1.017ms       3.198us           318  \n",
      "                                        aten::ones_like         0.04%       3.000us         0.23%      19.000us      19.000us             1  \n",
      "                                       aten::empty_like         0.02%       2.000us         0.07%       6.000us       6.000us             1  \n",
      "                                            aten::fill_         2.42%     200.000us         3.70%     306.000us       9.000us            34  \n",
      "                                             aten::diag         0.04%       3.000us         0.46%      38.000us      38.000us             1  \n",
      "                                       aten::diag_embed         0.07%       6.000us         0.42%      35.000us      35.000us             1  \n",
      "                                            aten::zeros         0.08%       7.000us         0.35%      29.000us      14.500us             2  \n",
      "                                            aten::empty         0.95%      79.000us         0.95%      79.000us       2.135us            37  \n",
      "                                            aten::zero_         0.06%       5.000us         0.19%      16.000us       8.000us             2  \n",
      "                                         aten::diagonal         0.02%       2.000us         0.02%       2.000us       2.000us             1  \n",
      "                                aten::repeat_interleave         0.43%      36.000us         5.01%     415.000us     103.750us             4  \n",
      "                                           aten::cumsum         0.43%      36.000us         0.58%      48.000us      24.000us             2  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us             8  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.01%       1.000us         0.01%       1.000us       0.004us           242  \n",
      "                                 cudaDeviceGetAttribute         0.00%       0.000us         0.00%       0.000us       0.000us           122  \n",
      "                                             aten::item         4.84%     401.000us        23.16%       1.918ms       8.963us           214  \n",
      "                              aten::_local_scalar_dense         5.68%     470.000us        21.68%       1.795ms       8.388us           214  \n",
      "                                               aten::ge         0.22%      18.000us         0.29%      24.000us      12.000us             2  \n",
      "                                              aten::all         0.23%      19.000us         0.31%      26.000us      13.000us             2  \n",
      "                                     aten::index_select         0.22%      18.000us         0.40%      33.000us      16.500us             2  \n",
      "                                          aten::resize_         0.77%      64.000us         0.77%      64.000us       2.000us            32  \n",
      "                                             aten::ones         0.05%       4.000us         0.19%      16.000us      16.000us             1  \n",
      "                                              aten::mul         2.75%     228.000us         4.06%     336.000us      11.200us            30  \n",
      "                                            aten::clamp         2.58%     214.000us         3.68%     305.000us      10.167us            30  \n",
      "                                             aten::topk         7.00%     580.000us         9.65%     799.000us      26.633us            30  \n",
      "                                  cudaFuncGetAttributes         0.60%      50.000us         0.60%      50.000us       1.667us            30  \n",
      "                                             aten::diff         1.27%     105.000us         7.50%     621.000us      20.700us            30  \n",
      "                                           aten::narrow         1.07%      89.000us         2.26%     187.000us       3.117us            60  \n",
      "                                            aten::slice         2.84%     235.000us         2.84%     235.000us       1.958us           120  \n",
      "                                              aten::sub         2.68%     222.000us         3.79%     314.000us      10.467us            30  \n",
      "                                              aten::abs         3.09%     256.000us         9.42%     780.000us      13.000us            60  \n",
      "                                           aten::argmax         3.99%     330.000us         5.86%     485.000us      16.167us            30  \n",
      "                                          aten::reshape         1.16%      96.000us         1.16%      96.000us       1.600us            60  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us            60  \n",
      "                                           aten::argmin         3.73%     309.000us         4.92%     407.000us      13.567us            30  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us            90  \n",
      "                                       aten::index_put_         0.65%      54.000us        12.37%       1.024ms      34.133us            30  \n",
      "                                 aten::_index_put_impl_         3.70%     306.000us        11.71%     970.000us      32.333us            30  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 8.280ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 18:58:12 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 18:58:12 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::resolve_conj         0.00%       1.000us         0.00%       1.000us       1.000us             1  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.32%     239.000us         7.26%       5.430ms       9.020us           602  \n",
      "                                         aten::_to_copy         1.39%       1.040ms         6.78%       5.071ms      16.847us           301  \n",
      "                                    aten::empty_strided         1.22%     914.000us         1.22%     914.000us       3.037us           301  \n",
      "                                            aten::copy_         3.50%       2.620ms         7.98%       5.971ms       9.935us           601  \n",
      "                                        cudaMemcpyAsync        17.22%      12.886ms        17.22%      12.886ms       5.367us          2401  \n",
      "                                  cudaStreamSynchronize         3.87%       2.899ms         3.87%       2.899ms       1.207us          2401  \n",
      "                                 aten::split_with_sizes         0.02%      18.000us         0.03%      21.000us      21.000us             1  \n",
      "                                       aten::as_strided         0.01%       4.000us         0.01%       4.000us       0.001us          4214  \n",
      "                                           aten::select         4.52%       3.379ms         4.52%       3.379ms       1.604us          2107  \n",
      "                                              aten::cat         0.04%      31.000us         0.07%      49.000us      49.000us             1  \n",
      "                                       cudaLaunchKernel        12.67%       9.477ms        12.67%       9.477ms       3.156us          3003  \n",
      "                                             aten::ones         0.01%       7.000us         0.03%      25.000us      25.000us             1  \n",
      "                                            aten::empty         0.82%     611.000us         0.82%     611.000us       2.023us           302  \n",
      "                                            aten::fill_         2.44%       1.824ms         3.67%       2.749ms       9.103us           302  \n",
      "                                            aten::zeros         0.01%       4.000us         0.02%      16.000us      16.000us             1  \n",
      "                                            aten::zero_         0.00%       2.000us         0.01%       9.000us       9.000us             1  \n",
      "                                              aten::add         2.83%       2.118ms         4.43%       3.314ms      11.047us           300  \n",
      "                                            aten::clamp         2.82%       2.110ms         4.03%       3.012ms      10.040us           300  \n",
      "                                             aten::topk         7.84%       5.867ms        10.50%       7.860ms      26.200us           300  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.001us          1200  \n",
      "                                  cudaFuncGetAttributes         0.50%     372.000us         0.50%     372.000us       1.240us           300  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%       1.000us         0.00%       1.000us       0.000us          2400  \n",
      "                                             aten::diff         1.18%     880.000us         7.89%       5.901ms      19.670us           300  \n",
      "                                           aten::narrow         1.23%     918.000us         2.44%       1.826ms       3.043us           600  \n",
      "                                            aten::slice         2.87%       2.146ms         2.87%       2.146ms       1.788us          1200  \n",
      "                                              aten::sub         2.84%       2.126ms         4.05%       3.028ms      10.093us           300  \n",
      "                                              aten::abs         3.30%       2.470ms        10.17%       7.606ms      12.677us           600  \n",
      "                                          aten::resize_         0.80%     602.000us         0.80%     602.000us       2.007us           300  \n",
      "                                           aten::argmax         8.21%       6.146ms        11.46%       8.577ms      14.295us           600  \n",
      "                                          aten::reshape         1.27%     948.000us         1.27%     952.000us       1.587us           600  \n",
      "                                   aten::_reshape_alias         0.01%       4.000us         0.01%       4.000us       0.007us           600  \n",
      "                                             aten::item         5.11%       3.823ms        24.51%      18.341ms       8.734us          2100  \n",
      "                              aten::_local_scalar_dense         6.33%       4.737ms        22.91%      17.141ms       8.162us          2100  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us           900  \n",
      "                                       aten::index_put_         0.86%     640.000us        13.41%      10.034ms      33.447us           300  \n",
      "                                 aten::_index_put_impl_         3.95%       2.957ms        12.81%       9.587ms      31.957us           300  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 74.822ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 18:58:13 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 18:58:13 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 18:58:13 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::resolve_conj         0.00%       1.000us         0.00%       1.000us       1.000us             1  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.28%     190.000us         7.73%       5.339ms       8.825us           605  \n",
      "                                         aten::_to_copy         1.61%       1.113ms         7.22%       4.988ms      16.571us           301  \n",
      "                                    aten::empty_strided         1.34%     924.000us         1.34%     924.000us       3.060us           302  \n",
      "                                            aten::copy_         3.69%       2.547ms         8.54%       5.894ms       9.791us           602  \n",
      "                                        cudaMemcpyAsync        18.23%      12.587ms        18.23%      12.587ms       5.234us          2405  \n",
      "                                  cudaStreamSynchronize         3.74%       2.580ms         3.74%       2.580ms       1.073us          2405  \n",
      "                                 aten::split_with_sizes         0.03%      19.000us         0.03%      23.000us      23.000us             1  \n",
      "                                       aten::as_strided         0.02%      12.000us         0.02%      12.000us       0.003us          3919  \n",
      "                                           aten::select         4.57%       3.156ms         4.58%       3.163ms       1.313us          2409  \n",
      "                                              aten::cat         0.04%      30.000us         0.07%      50.000us      50.000us             1  \n",
      "                                       cudaLaunchKernel        12.43%       8.585ms        12.43%       8.585ms       3.159us          2718  \n",
      "                                        aten::ones_like         0.01%       5.000us         0.04%      27.000us      27.000us             1  \n",
      "                                       aten::empty_like         0.00%       2.000us         0.01%       8.000us       8.000us             1  \n",
      "                                            aten::fill_         2.98%       2.056ms         4.38%       3.025ms       9.951us           304  \n",
      "                                             aten::diag         0.07%      46.000us         0.07%      46.000us      46.000us             1  \n",
      "                                       aten::diag_embed         0.01%       9.000us         0.06%      44.000us      44.000us             1  \n",
      "                                            aten::zeros         0.01%       8.000us         0.04%      31.000us      15.500us             2  \n",
      "                                            aten::empty         0.90%     624.000us         0.90%     624.000us       2.033us           307  \n",
      "                                            aten::zero_         0.01%       4.000us         0.02%      16.000us       8.000us             2  \n",
      "                                         aten::diagonal         0.00%       2.000us         0.00%       2.000us       2.000us             1  \n",
      "                                aten::repeat_interleave         0.05%      37.000us         0.71%     492.000us     123.000us             4  \n",
      "                                           aten::cumsum         0.06%      41.000us         0.08%      58.000us      29.000us             2  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us             8  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%       2.000us         0.00%       2.000us       0.001us          2402  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.001us          1202  \n",
      "                                             aten::item         4.26%       2.943ms        26.02%      17.968ms       8.540us          2104  \n",
      "                              aten::_local_scalar_dense         6.86%       4.739ms        23.91%      16.512ms       7.848us          2104  \n",
      "                                               aten::ge         0.03%      24.000us         0.05%      32.000us      16.000us             2  \n",
      "                                              aten::all         0.03%      24.000us         0.04%      30.000us      15.000us             2  \n",
      "                                     aten::index_select         0.03%      22.000us         0.06%      39.000us      19.500us             2  \n",
      "                                          aten::resize_         0.88%     609.000us         0.88%     609.000us       2.017us           302  \n",
      "                                             aten::ones         0.01%       5.000us         0.02%      17.000us      17.000us             1  \n",
      "                                              aten::add         3.09%       2.132ms         4.79%       3.306ms      11.020us           300  \n",
      "                                            aten::clamp         3.06%       2.113ms         4.37%       3.017ms      10.057us           300  \n",
      "                                             aten::topk         8.31%       5.738ms        11.04%       7.626ms      25.420us           300  \n",
      "                                  cudaFuncGetAttributes         0.47%     323.000us         0.47%     323.000us       1.077us           300  \n",
      "                                             aten::diff         1.13%     782.000us         8.42%       5.816ms      19.387us           300  \n",
      "                                           aten::narrow         1.28%     882.000us         2.64%       1.820ms       3.033us           600  \n",
      "                                            aten::slice         2.52%       1.741ms         2.52%       1.741ms       1.934us           900  \n",
      "                                              aten::sub         3.05%       2.108ms         4.36%       3.011ms      10.037us           300  \n",
      "                                              aten::abs         3.55%       2.448ms        10.93%       7.547ms      12.578us           600  \n",
      "                                           aten::argmax         4.52%       3.121ms         6.70%       4.628ms      15.427us           300  \n",
      "                                          aten::reshape         1.34%     922.000us         1.34%     922.000us       1.537us           600  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us           600  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us           900  \n",
      "                                       aten::index_put_         1.27%     880.000us        14.43%       9.963ms      33.210us           300  \n",
      "                                 aten::_index_put_impl_         4.22%       2.913ms        13.67%       9.439ms      31.463us           300  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 69.050ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    mask=torch.ones(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    finder,replaceval=(torch.argmax,0) if maximize else (torch.argmin,float(1e9))\n",
    "    for _ in range(row_lookups.shape[0]): # number of columns\n",
    "        deltas=torch.diff(torch.topk(torch.clamp(Batched_TruthTensor*mask,max=100),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0])) \n",
    "        row_index=finder(Batched_TruthTensor[:,col_index],dim=0) # BxB\n",
    "        mask[:,col_index]=replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=replaceval\n",
    "        results[row_index,col_index]=1\n",
    "    return results\n",
    "\n",
    "# We have 2 methods, taking the row and col index via hooks\n",
    "# we can generate the row col index with argmax or use the original sort method.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "\n",
    "class LinearSumAssignmentModule(nn.Module):\n",
    "    def __init__(self,maximize=True,version=2):\n",
    "        super(LinearSumAssignmentModule,self).__init__()\n",
    "        self.lookahead=2\n",
    "        self.finder,self.replaceval=(torch.argmax,float('-inf')) if maximize else (torch.argmin,float('inf'))\n",
    "        self.topk=partial(torch.topk,largest=maximize)\n",
    "        self.do_step=self.do_step_v2 if version==2 else self.do_step_v1\n",
    "    def do_step_v1(self,C,mask,results,row_lookups):\n",
    "        col_topks_v,col_topks_i=self.topk(torch.clamp(C+mask,max=100),self.lookahead,dim=0)\n",
    "        deltas=torch.diff(col_topks_v,n=self.lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0]))\n",
    "        row_index=col_topks_i[0][col_index]\n",
    "        mask[:,col_index]=self.replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=self.replaceval\n",
    "        results[row_index,col_index]=1\n",
    "        return C,mask,results\n",
    "    \n",
    "    def do_step_v2(self,C,mask,results,row_lookups):\n",
    "        col_topks_v,col_topks_i=self.topk(torch.clamp(C+mask,max=100),self.lookahead,dim=0)\n",
    "        deltas=torch.diff(col_topks_v,n=self.lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0]))\n",
    "        row_index=self.finder(C[:,col_index],dim=0)\n",
    "        mask[:,col_index]=self.replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=self.replaceval\n",
    "        results[row_index,col_index]=1\n",
    "        return C,mask,results\n",
    "    def forward(self,C:torch.Tensor,row_lookups:torch.Tensor):\n",
    "        mask=torch.ones(C.shape,device=C.device)\n",
    "        results=torch.zeros(C.shape,device=C.device)\n",
    "        for _ in range(C.shape[0]):\n",
    "            C,mask,results=self.do_step(C,mask,results,row_lookups)\n",
    "        return results\n",
    "    \n",
    "\n",
    "#comparison\n",
    "my_module=LinearSumAssignmentModule(maximize=True,version=2).cuda()\n",
    "my_module2=LinearSumAssignmentModule(maximize=True,version=1).cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def lookup_sizes_vfast(sizes:torch.Tensor):\n",
    "    return torch.diag(torch.ones_like(sizes)).repeat_interleave(sizes,dim=0).repeat_interleave(sizes,dim=1).to(dtype=torch.long,device=sizes.device)\n",
    "\n",
    "\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,300,30)).cuda()\n",
    "sizes=torch.tensor([5,4,3,4,5,4,5],device=Batched_TestTensor.device)\n",
    "\n",
    "fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "row_lookups=lookup_sizes_vfast(sizes)\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1).to(device=\"cuda\")\n",
    "    row_lookups=lookup_sizes_vfast(sizes)\n",
    "    outputs=Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1).to(device=\"cuda\")\n",
    "\n",
    "    outputs=my_module(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1).to(device=\"cuda\")\n",
    "\n",
    "    outputs=my_module2(fx,row_lookups=lookup_sizes_vfast(sizes))\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          aten::nonzero         7.78%      59.000us        15.17%     115.000us     115.000us      84.000us        10.82%     117.000us     117.000us           0 b           0 b       8.50 Kb           0 b             1  \n",
      "                                aten::repeat_interleave        12.66%      96.000us        73.09%     554.000us     277.000us      79.000us        10.18%     562.000us     281.000us           0 b           0 b      22.00 Kb      -6.00 Kb             2  \n",
      "                                            aten::index         9.37%      71.000us        30.08%     228.000us     228.000us      66.000us         8.51%     235.000us     235.000us           0 b           0 b     839.50 Kb     831.00 Kb             1  \n",
      "                                            aten::fill_         2.24%      17.000us         5.01%      38.000us      19.000us      46.000us         5.93%      46.000us      23.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::cumsum         4.49%      34.000us         6.07%      46.000us      46.000us      46.000us         5.93%      49.000us      49.000us           0 b           0 b         512 b         512 b             1  \n",
      "                              aten::_local_scalar_dense         0.79%       6.000us         4.49%      34.000us      17.000us      39.000us         5.03%      39.000us      19.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                     aten::index_select         4.09%      31.000us         5.54%      42.000us      42.000us      34.000us         4.38%      45.000us      45.000us           0 b           0 b      17.50 Kb           0 b             1  \n",
      "                                              aten::all         3.43%      26.000us         4.09%      31.000us      31.000us      32.000us         4.12%      35.000us      35.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                       aten::as_strided         0.79%       6.000us         0.79%       6.000us       0.750us      31.000us         3.99%      31.000us       3.875us           0 b           0 b           0 b           0 b             8  \n",
      "                                           aten::select         3.83%      29.000us         3.83%      29.000us       9.667us      30.000us         3.87%      39.000us      13.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                               aten::ge         2.51%      19.000us         3.17%      24.000us      24.000us      27.000us         3.48%      27.000us      27.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                       aten::diag_embed         3.83%      29.000us        13.19%     100.000us     100.000us      23.000us         2.96%     103.000us     103.000us           0 b           0 b       1.50 Kb           0 b             1  \n",
      "                                    aten::empty_strided         2.24%      17.000us         2.24%      17.000us      17.000us      22.000us         2.84%      22.000us      22.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                            aten::copy_         1.72%      13.000us         2.37%      18.000us      18.000us      22.000us         2.84%      22.000us      22.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                          aten::permute         2.77%      21.000us         3.43%      26.000us      26.000us      21.000us         2.71%      30.000us      30.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::empty         1.45%      11.000us         1.45%      11.000us       3.667us      21.000us         2.71%      21.000us       7.000us           0 b           0 b       6.00 Kb       6.00 Kb             3  \n",
      "                                          aten::reshape         2.77%      21.000us         2.77%      21.000us      10.500us      19.000us         2.45%      27.000us      13.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                        aten::ones_like         2.51%      19.000us        10.82%      82.000us      82.000us      16.000us         2.06%      86.000us      86.000us           0 b           0 b         512 b           0 b             1  \n",
      "                                            aten::zeros         2.51%      19.000us         5.54%      42.000us      42.000us      15.000us         1.93%      45.000us      45.000us           0 b           0 b       1.50 Kb           0 b             1  \n",
      "                                             aten::item         2.11%      16.000us         6.60%      50.000us      25.000us      15.000us         1.93%      54.000us      27.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                       aten::empty_like         1.98%      15.000us         4.22%      32.000us      32.000us      13.000us         1.68%      35.000us      35.000us           0 b           0 b         512 b           0 b             1  \n",
      "                                          aten::resize_         0.79%       6.000us         0.79%       6.000us       3.000us      12.000us         1.55%      12.000us       6.000us           0 b           0 b      26.00 Kb      26.00 Kb             2  \n",
      "                                         aten::diagonal         1.45%      11.000us         1.45%      11.000us      11.000us      10.000us         1.29%      13.000us      13.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::diag         1.19%       9.000us        14.38%     109.000us     109.000us       9.000us         1.16%     112.000us     112.000us           0 b           0 b       1.50 Kb           0 b             1  \n",
      "                                            aten::zero_         1.32%      10.000us         2.24%      17.000us      17.000us       9.000us         1.16%      20.000us      20.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                                aten::t         1.19%       9.000us         2.51%      19.000us      19.000us       9.000us         1.16%      22.000us      22.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                        aten::transpose         1.19%       9.000us         1.32%      10.000us      10.000us       9.000us         1.16%      13.000us      13.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us       8.000us         1.03%       8.000us       4.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::set_         1.58%      12.000us         1.58%      12.000us      12.000us       6.000us         0.77%       6.000us       6.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         0.39%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cudaLaunchKernel         9.63%      73.000us         9.63%      73.000us       4.867us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            15  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b   -1005.50 Kb   -1005.50 Kb             4  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.40%       3.000us         0.40%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                 cudaDeviceGetAttribute         0.13%       1.000us         0.13%       1.000us       0.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                        cudaMemcpyAsync         4.22%      32.000us         4.22%      32.000us      10.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                  cudaStreamSynchronize         0.53%       4.000us         0.53%       4.000us       1.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                  cudaDeviceSynchronize         0.53%       4.000us         0.53%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 758.000us\n",
      "Self CUDA time total: 776.000us\n",
      "\n",
      "torch.Size([537, 400])\n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              aten::select        42.76%     301.000us        42.76%     301.000us       9.121us     298.000us        35.73%     411.000us      12.455us           0 b           0 b           0 b           0 b            33  \n",
      "          aten::as_strided         0.28%       2.000us         0.28%       2.000us       0.030us     220.000us        26.38%     220.000us       3.333us           0 b           0 b           0 b           0 b            66  \n",
      "    aten::split_with_sizes        40.91%     288.000us        41.19%     290.000us     290.000us     187.000us        22.42%     294.000us     294.000us           0 b           0 b           0 b           0 b             1  \n",
      "                 aten::cat         3.41%      24.000us         4.83%      34.000us      34.000us      42.000us         5.04%      42.000us      42.000us           0 b           0 b     839.50 Kb     839.50 Kb             1  \n",
      "               aten::copy_         1.42%      10.000us         3.84%      27.000us      27.000us      31.000us         3.72%      31.000us      31.000us           0 b           0 b           0 b           0 b             1  \n",
      "            aten::_to_copy         4.26%      30.000us         9.09%      64.000us      64.000us      25.000us         3.00%      68.000us      68.000us         264 b           0 b           0 b           0 b             1  \n",
      "                  aten::to         1.70%      12.000us        10.80%      76.000us      76.000us      12.000us         1.44%      80.000us      80.000us         264 b           0 b           0 b           0 b             1  \n",
      "       aten::empty_strided         0.99%       7.000us         0.99%       7.000us       7.000us      12.000us         1.44%      12.000us      12.000us         264 b         264 b           0 b           0 b             1  \n",
      "        aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.48%       4.000us       4.000us           0 b           0 b           0 b           0 b             1  \n",
      "         aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         0.36%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "           cudaMemcpyAsync         2.13%      15.000us         2.13%      15.000us      15.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "     cudaStreamSynchronize         0.28%       2.000us         0.28%       2.000us       2.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                  [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us        -264 b        -264 b    -986.00 Kb    -986.00 Kb             2  \n",
      "          cudaLaunchKernel         1.42%      10.000us         1.42%      10.000us      10.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "     cudaDeviceSynchronize         0.43%       3.000us         0.43%       3.000us       3.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 704.000us\n",
      "Self CUDA time total: 834.000us\n",
      "\n",
      "torch.Size([400, 537])\n",
      "tensor(True, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_ints=33\n",
    "ints=torch.randint(0,40,(num_ints,)).to(\"cuda\")\n",
    "sum_of_ints=ints.sum()\n",
    "Batched_TestTensor=torch.rand((num_ints,400,sum_of_ints)).cuda()\n",
    "sizes=ints\n",
    "\n",
    "\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, record_shapes=True, with_flops=True, profile_memory=True) as prof: \n",
    "    fx2=Batched_TestTensor.permute(0,2,1)[torch.diag(torch.ones_like(sizes,dtype=torch.bool)).repeat_interleave(sizes,dim=1)]\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(fx2.shape)\n",
    "with torch.autograd.profiler.profile(use_cuda=True, record_shapes=True, with_flops=True, profile_memory=True) as prof: \n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(fx.shape)\n",
    "\n",
    "\n",
    "check=fx2==fx.T\n",
    "print(check.all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
