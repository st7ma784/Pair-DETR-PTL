{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is going to explore linear sum assignment. This is a problem that comes up in many different contexts.  For example, you might want to assign workers to tasks, or you might want to assign students to projects.  In this notebook, we'll look at a few different ways to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "TestTensor=torch.rand((300,20))\n",
    "\n",
    "plt.imshow(TestTensor.pow(5),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TruthIndices=linear_sum_assignment(TestTensor.numpy(), maximize=True)\n",
    "\n",
    "plt.imshow(TestTensor)\n",
    "plt.scatter(TruthIndices[1],TruthIndices[0],c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W collection.cpp:258] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W collection.cpp:258] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W profiler_kineto.cpp:495] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W collection.cpp:258] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W profiler_kineto.cpp:495] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W profiler_kineto.cpp:495] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W collection.cpp:258] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W collection.cpp:258] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W collection.cpp:258] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W profiler_kineto.cpp:495] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W collection.cpp:258] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W profiler_kineto.cpp:495] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W profiler_kineto.cpp:495] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n",
      "[W profiler_kineto.cpp:495] Failed to record CUDA event. ../torch/csrc/profiler/stubs/cuda.cpp:46: device-side assert triggered\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Documents/Pair-DETR-PTL/LinearSumAssignment.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/home/user/Documents/Pair-DETR-PTL/LinearSumAssignment.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\u001b[39m.\u001b[39mnonzero(as_tuple\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/home/user/Documents/Pair-DETR-PTL/LinearSumAssignment.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m TestTensor\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mrand((\u001b[39m60\u001b[39m,\u001b[39m200\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/home/user/Documents/Pair-DETR-PTL/LinearSumAssignment.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m TestTensor\u001b[39m=\u001b[39mTestTensor\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/home/user/Documents/Pair-DETR-PTL/LinearSumAssignment.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m#time this \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/home/user/Documents/Pair-DETR-PTL/LinearSumAssignment.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m \n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "def LinearSumAssignmentLoss(TruthIndices, PredictedIndices):\n",
    "    return torch.sum(torch.pow(TruthIndices-PredictedIndices,2))\n",
    "\n",
    "\n",
    "###\n",
    "'''\n",
    "Linear sum assignment stages:\n",
    "Step 1: Sort the tensor by the columns, max value at the top\n",
    "#Step 2 (Optional) crop max values down to a square\n",
    "Step 3: take top 2 rows and find the biggest delta in the vertical direction and select that Value\n",
    "step 4: mark out everything on that row and column as not selectable \n",
    "'''\n",
    "\n",
    "\n",
    "@torch.jit.script_if_tracing\n",
    "def MyLinearSumAssignment(TruthTensor, maximize=True,lookahead=2):\n",
    "    '''\n",
    "    If Maximize is False, I'm trying to minimize the costs. \n",
    "    This means that the mask must instead make all the weights far above all the others - 'inf' kind of thing. \n",
    "    '''\n",
    "    #assert truthtensor is 2d and nonzero\n",
    "    assert len(TruthTensor.shape)==2\n",
    "    assert TruthTensor.shape[0]>0 and TruthTensor.shape[1]>0\n",
    "    assert lookahead>0\n",
    "    assert torch.sum(TruthTensor==0)==0\n",
    "\n",
    "    mask=torch.zeros(TruthTensor.shape,device=TruthTensor.device,dtype=torch.bool)\n",
    "    results=torch.zeros(TruthTensor.shape,device=TruthTensor.device)\n",
    "\n",
    "    finder=torch.argmax if maximize else torch.argmin\n",
    "    \n",
    "    TruthTensor=TruthTensor-torch.min(TruthTensor)\n",
    "    replaceval=0 if maximize else torch.max(TruthTensor)+1\n",
    "\n",
    "    \n",
    "    for i in range(min(TruthTensor.shape[-2:])): # number of rows\n",
    "        deltas=torch.diff(torch.topk(torch.where(mask,replaceval,TruthTensor),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas),dim=1) # this is the column to grab,  Note this measures step so its not important to do argmin...\n",
    "        row_index=finder(TruthTensor[:,col_index])\n",
    "        mask[:,col_index]=True #mask out the column\n",
    "        mask[row_index]=True\n",
    "        results[row_index,col_index]=1\n",
    "    assert torch.sum(results)==min(TruthTensor.shape[-2:]) # we should have found a result for every row and column\n",
    "    # check no rows or columns are duplicated\n",
    "    assert torch.sum(torch.sum(results,dim=0)>1)==0\n",
    "    assert torch.sum(torch.sum(results,dim=1)>1)==0\n",
    "    return results.nonzero(as_tuple=True) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TestTensor=torch.rand((60,200))\n",
    "TestTensor=TestTensor.to(\"cuda\")\n",
    "#time this \n",
    "import time \n",
    "\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "X,Y= linear_sum_assignment(TestTensor.cpu().numpy(), maximize=True)\n",
    "X=torch.from_numpy(X).to(\"cuda\")\n",
    "Y=torch.from_numpy(Y).to(\"cuda\")\n",
    "end=time.time()-start\n",
    "print(\"scipy took:\",end)\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    x,y= MyLinearSumAssignment(TestTensor,maximize=True)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "\n",
    "\n",
    "#do intersection over union\n",
    "print(len(set(zip(x,y)).intersection(set(zip(X,Y))))/len(set(zip(x,y)).union(set(zip(X,Y)))))\n",
    "#sum of scores at those indices\n",
    "\n",
    "plt.imshow(TestTensor.cpu().numpy())\n",
    "plt.scatter(y.cpu().numpy(),x.cpu().numpy(),c='r')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(TestTensor.cpu().numpy())\n",
    "plt.scatter(Y.cpu().numpy(),X.cpu().numpy(),c='b')\n",
    "plt.show()\n",
    "\n",
    "print(TestTensor[x,y].sum())\n",
    "\n",
    "print(TestTensor[X,Y].sum())\n",
    "\n",
    "\n",
    "x,y=x.tolist(),y.tolist()\n",
    "X,Y=X.tolist(),Y.tolist()\n",
    "print(set(zip(x,y)))\n",
    "print(set(zip(X,Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    MyLinearSumAssignment(torch.rand((20,80)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched runtimes. The linear sum assignment in use actually runs cpu bound as\n",
    "\n",
    "batched_indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(tgt_sizes.tolist(), -1))]\n",
    "\n",
    "It's actually quite useful to see if theres a way to parallelize this. I'm not sure if there is, but it's worth looking into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original method took: 0.0015871524810791016\n",
      "[(array([ 81, 105, 165, 172, 191]), array([2, 0, 3, 4, 1])), (array([ 89, 187, 206, 251]), array([3, 1, 2, 0])), (array([104, 156, 235]), array([1, 2, 0])), (array([ 63,  76, 222, 298]), array([2, 0, 3, 1])), (array([  9,  20, 143, 153, 179]), array([4, 1, 2, 3, 0])), (array([ 16,  57, 122, 150]), array([2, 1, 0, 3])), (array([123, 151, 204, 282, 288]), array([4, 3, 1, 0, 2]))]\n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           aten::resolve_conj         0.03%       2.000us         0.03%       2.000us       2.000us             1  \n",
      "            aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "       aten::split_with_sizes         0.42%      30.000us         0.54%      38.000us      38.000us             1  \n",
      "             aten::as_strided         0.17%      12.000us         0.17%      12.000us       0.027us           448  \n",
      "                 aten::select         7.56%     535.000us         7.59%     537.000us       2.430us           221  \n",
      "                    aten::cat         0.96%      68.000us         1.29%      91.000us      91.000us             1  \n",
      "                 aten::narrow         2.29%     162.000us         4.62%     327.000us       4.881us            67  \n",
      "                  aten::slice         4.96%     351.000us         4.99%     353.000us       2.780us           127  \n",
      "              aten::ones_like         0.07%       5.000us         0.21%      15.000us      15.000us             1  \n",
      "             aten::empty_like         0.04%       3.000us         0.10%       7.000us       7.000us             1  \n",
      "          aten::empty_strided         0.06%       4.000us         0.06%       4.000us       4.000us             1  \n",
      "                  aten::fill_         1.48%     105.000us         1.91%     135.000us       3.971us            34  \n",
      "                   aten::diag         0.24%      17.000us         0.64%      45.000us      45.000us             1  \n",
      "             aten::diag_embed         0.16%      11.000us         0.40%      28.000us      28.000us             1  \n",
      "                  aten::zeros         0.11%       8.000us         0.20%      14.000us       7.000us             2  \n",
      "                  aten::empty         0.49%      35.000us         0.49%      35.000us       0.946us            37  \n",
      "                  aten::zero_         0.04%       3.000us         0.04%       3.000us       1.500us             2  \n",
      "               aten::diagonal         0.06%       4.000us         0.06%       4.000us       4.000us             1  \n",
      "                  aten::copy_         0.96%      68.000us         0.96%      68.000us       2.194us            31  \n",
      "      aten::repeat_interleave         1.07%      76.000us         3.76%     266.000us      66.500us             4  \n",
      "                 aten::cumsum         0.16%      11.000us         0.16%      11.000us       5.500us             2  \n",
      "                     aten::to         0.00%       0.000us         0.00%       0.000us       0.000us            33  \n",
      "                   aten::item         3.05%     216.000us         3.07%     217.000us       1.014us           214  \n",
      "    aten::_local_scalar_dense         0.03%       2.000us         0.03%       2.000us       0.009us           214  \n",
      "                     aten::ge         0.17%      12.000us         0.17%      12.000us       6.000us             2  \n",
      "                    aten::all         0.20%      14.000us         0.20%      14.000us       7.000us             2  \n",
      "           aten::index_select         0.35%      25.000us         0.41%      29.000us      14.500us             2  \n",
      "                   aten::ones         0.08%       6.000us         0.17%      12.000us      12.000us             1  \n",
      "                    aten::mul         2.95%     209.000us         2.95%     209.000us       6.967us            30  \n",
      "                  aten::clamp         9.28%     657.000us         9.28%     657.000us      21.900us            30  \n",
      "                   aten::topk        38.07%       2.695ms        38.07%       2.695ms      89.833us            30  \n",
      "                   aten::diff         1.86%     132.000us         8.12%     575.000us      19.167us            30  \n",
      "                    aten::sub         1.85%     131.000us         1.85%     131.000us       4.367us            30  \n",
      "                    aten::abs         2.63%     186.000us         4.12%     292.000us       4.867us            60  \n",
      "                 aten::argmax         4.46%     316.000us         5.64%     399.000us      13.300us            30  \n",
      "                aten::reshape         2.01%     142.000us         2.03%     144.000us       2.400us            60  \n",
      "         aten::_reshape_alias         0.03%       2.000us         0.03%       2.000us       0.033us            60  \n",
      "                 aten::argmin         7.53%     533.000us         7.53%     533.000us      17.767us            30  \n",
      "             aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us            90  \n",
      "             aten::index_put_         0.97%      69.000us         4.97%     352.000us      11.733us            30  \n",
      "       aten::_index_put_impl_         3.14%     222.000us         4.00%     283.000us       9.433us            30  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.079ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-10-23 11:40:19 1006965:1006965 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-10-23 11:40:19 1006965:1006965 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-10-23 11:40:19 1006965:1006965 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-10-23 11:40:19 1006965:1006965 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-10-23 11:40:19 1006965:1006965 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-10-23 11:40:19 1006965:1006965 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  aten::empty         0.02%       8.000us         0.02%       8.000us       0.013us           603  \n",
      "                     aten::to         0.76%     354.000us         4.33%       2.016ms       2.352us           857  \n",
      "             aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                aten::detach_         0.01%       3.000us         0.01%       5.000us       1.667us             3  \n",
      "                      detach_         0.00%       2.000us         0.00%       2.000us       0.667us             3  \n",
      "              aten::ones_like         1.06%     492.000us         2.65%       1.232ms       4.107us           300  \n",
      "             aten::empty_like         0.62%     287.000us         0.94%     438.000us       1.460us           300  \n",
      "          aten::empty_strided         0.67%     314.000us         0.67%     314.000us       0.523us           600  \n",
      "                  aten::fill_         0.67%     312.000us         0.67%     312.000us       1.040us           300  \n",
      "                  aten::index        13.37%       6.224ms        14.69%       6.838ms      11.397us           600  \n",
      "             aten::as_strided         0.01%       3.000us         0.01%       3.000us       0.001us          5396  \n",
      "                aten::reshape         3.27%       1.520ms         3.27%       1.521ms       1.014us          1500  \n",
      "         aten::_reshape_alias         0.00%       1.000us         0.00%       1.000us       0.001us          1500  \n",
      "                     aten::gt         3.41%       1.586ms         3.41%       1.586ms       5.287us           300  \n",
      "                  aten::where         5.92%       2.756ms        10.91%       5.076ms      16.920us           300  \n",
      "               aten::_to_copy         1.81%     841.000us         3.91%       1.820ms       6.067us           300  \n",
      "                  aten::copy_         2.15%       1.000ms         2.15%       1.000ms       3.333us           300  \n",
      "             aten::index_put_         1.87%     869.000us        21.99%      10.237ms      17.062us           600  \n",
      "       aten::_index_put_impl_        19.03%       8.858ms        20.33%       9.461ms      15.768us           600  \n",
      "                  aten::slice         5.10%       2.375ms         5.10%       2.375ms       0.991us          2396  \n",
      "                    aten::mul         2.50%       1.162ms         2.50%       1.162ms       3.873us           300  \n",
      "                  aten::clamp         2.35%       1.093ms         2.35%       1.093ms       3.643us           300  \n",
      "                   aten::topk        12.30%       5.727ms        12.30%       5.727ms      19.090us           300  \n",
      "                   aten::diff         1.81%     844.000us         6.10%       2.838ms       9.460us           300  \n",
      "                 aten::narrow         4.13%       1.924ms         6.73%       3.134ms       1.745us          1796  \n",
      "                    aten::sub         0.82%     382.000us         0.82%     382.000us       1.273us           300  \n",
      "                 aten::select         1.96%     912.000us         1.96%     912.000us       1.520us           600  \n",
      "                    aten::abs         1.98%     921.000us         2.62%       1.220ms       2.033us           600  \n",
      "                 aten::argmax         2.60%       1.209ms         3.26%       1.516ms       5.053us           300  \n",
      "              aten::unsqueeze         1.32%     613.000us         1.32%     613.000us       1.022us           600  \n",
      "                    aten::cat         5.87%       2.733ms         9.64%       4.489ms       7.482us           600  \n",
      "                   aten::item         0.64%     300.000us         0.65%     301.000us       1.003us           300  \n",
      "    aten::_local_scalar_dense         0.00%       1.000us         0.00%       1.000us       0.003us           300  \n",
      "                 aten::argmin         1.96%     912.000us         1.96%     912.000us       3.040us           300  \n",
      "                   aten::view         0.02%       8.000us         0.02%       8.000us       8.000us             1  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 46.546ms\n",
      "\n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         aten::unsqueeze         0.87%      15.000us         1.16%      20.000us      20.000us             1  \n",
      "        aten::as_strided         0.46%       8.000us         0.46%       8.000us       0.615us            13  \n",
      "            aten::repeat        62.70%       1.081ms        70.30%       1.212ms       1.212ms             1  \n",
      "            aten::expand         0.29%       5.000us         0.29%       5.000us       2.500us             2  \n",
      "             aten::empty         0.46%       8.000us         0.46%       8.000us       4.000us             2  \n",
      "             aten::alias         0.06%       1.000us         0.06%       1.000us       1.000us             1  \n",
      "            aten::unfold         0.35%       6.000us         0.41%       7.000us       2.333us             3  \n",
      "         aten::expand_as         0.06%       1.000us         0.17%       3.000us       3.000us             1  \n",
      "             aten::copy_         6.21%     107.000us         6.21%     107.000us     107.000us             1  \n",
      "             aten::clamp         4.18%      72.000us         4.18%      72.000us      72.000us             1  \n",
      "                aten::to         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "              aten::topk        18.33%     316.000us        18.33%     316.000us     316.000us             1  \n",
      "              aten::diff         0.46%       8.000us         2.15%      37.000us      37.000us             1  \n",
      "            aten::narrow         0.41%       7.000us         0.81%      14.000us       7.000us             2  \n",
      "             aten::slice         0.52%       9.000us         0.52%       9.000us       3.000us             3  \n",
      "               aten::sub         0.87%      15.000us         0.87%      15.000us      15.000us             1  \n",
      "          aten::diagonal         0.29%       5.000us         0.29%       5.000us       2.500us             2  \n",
      "               aten::abs         0.64%      11.000us         1.04%      18.000us       9.000us             2  \n",
      "            aten::argmax         0.99%      17.000us         0.99%      17.000us      17.000us             1  \n",
      "             aten::index         1.51%      26.000us         1.86%      32.000us      32.000us             1  \n",
      "           aten::reshape         0.35%       6.000us         0.35%       6.000us       6.000us             1  \n",
      "    aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.724ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-10-23 11:40:21 1006965:1006965 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-10-23 11:40:21 1006965:1006965 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-10-23 11:40:21 1006965:1006965 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "def original_method(C: torch.Tensor,sizes: torch.Tensor):\n",
    "    return [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes.tolist(), -1))]\n",
    "\n",
    "##I want to know if theres optimizations in this if I rewrite it to do this at each step\n",
    "@torch.no_grad()\n",
    "def lookup_sizes(sizes:torch.Tensor):\n",
    "    mask=torch.zeros((sizes.sum(),sizes.sum()),device=sizes.device)\n",
    "    start=0\n",
    "    for i in range(len(sizes)):\n",
    "        mask[start:start+sizes[i],start:start+sizes[i]]=1\n",
    "        start+=sizes[i]\n",
    "    plt.imshow(mask)\n",
    "    return mask.bool()\n",
    "\n",
    "@torch.no_grad()\n",
    "def lookup_sizes_vfast(sizes:torch.Tensor):\n",
    "    return torch.diag(torch.ones_like(sizes)).repeat_interleave(sizes,dim=0).repeat_interleave(sizes,dim=1).to(dtype=torch.long,device=sizes.device)\n",
    "\n",
    "@torch.no_grad()\n",
    "#@torch.jit.script\n",
    "def Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    mask=torch.ones(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    finder,replaceval=(torch.argmax,0) if maximize else (torch.argmin,float(1e9))\n",
    "    for _ in range(row_lookups.shape[0]): # number of columns\n",
    "        deltas=torch.diff(torch.topk(torch.clamp(Batched_TruthTensor*mask,max=100),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0])) \n",
    "        row_index=finder(Batched_TruthTensor[:,col_index],dim=0) # BxB\n",
    "        mask[:,col_index]=replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=replaceval\n",
    "        results[row_index,col_index]=1\n",
    "    return results\n",
    "@torch.no_grad()\n",
    "#@torch.jit.script\n",
    "def in_place_Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    #results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    finder,replaceval=(torch.argmax,torch.tensor(0)) if maximize else (torch.argmin,torch.tensor(1e9))\n",
    "    r=torch.tensor([],dtype=torch.long,device=Batched_TruthTensor.device)\n",
    "    c=torch.tensor([],dtype=torch.long,device=Batched_TruthTensor.device)\n",
    "\n",
    "    for i_ in range(Batched_TruthTensor.shape[0]): # number of columns\n",
    "        col_index=torch.argmax(torch.abs(torch.diff(torch.topk(torch.clamp(Batched_TruthTensor*calculate_mask(Batched_TruthTensor,r,c,row_lookups,replaceval=replaceval),max=100),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)[0]))\n",
    "        c=torch.cat([c,col_index.unsqueeze(0)])\n",
    "        r=torch.cat([r,finder(Batched_TruthTensor[:,col_index],dim=0).unsqueeze(0)])\n",
    "    return r,c\n",
    "\n",
    "def no_for_loop_Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    #We're going to first make our cube, which will be BxBxB\n",
    "    #We're going to do this by making a BxB matrix, and then repeating it B times\n",
    "    #results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device).unsqueeze(-1).repeat(1,1,Batched_TruthTensor.shape[-1])\n",
    "    #our first the first set of deltas will be the topk of the first BxB matrix\n",
    "    #finder=(torch.argmax,torch.argmin)[maximize]\n",
    "\n",
    "\n",
    "    #for n in nth slice of cube, I want to find the biggest gap between the max and nth highest value in the column \n",
    "    topk_values,topk_ind=torch.topk(torch.clamp(Batched_TruthTensor.unsqueeze(-1).repeat(1,1,Batched_TruthTensor.shape[-1]),max=100),k=Batched_TruthTensor.shape[-1],dim=0,largest=maximize)\n",
    "    #shape is BxBxB\n",
    "    #for each slice of the cube, I want to find the biggest gap between the max and nth highest value in the column so the shape is BxB\n",
    "    #print(\"values\",topk_values.shape)\n",
    "    #fulldeltas=torch.stack([\n",
    "    #                    torch.diff(topk_values[:,:,n],n=n,dim=0)[0]\n",
    "    #                    for n in range(Batched_TruthTensor.shape[-1])],dim=0)\n",
    "    #print(\"fulldeltas\",fulldeltas.shape) # these are the deltas for each column, from the maximum value to the nth highest value going down the column\n",
    "    #shape is BxB    \n",
    "    deltas=torch.diff(topk_values,n=1,dim=0)\n",
    "    \n",
    "    selection=deltas.diagonal(dim1=1,dim2=2) # this is the difference between the nth highest value and the n+1th highest value in the column\n",
    "\n",
    "    col_index=torch.argmax(torch.abs(selection),dim=0,keepdim=False)\n",
    "    #This should find the column with the biggest gap in the cube and be in the form _,_,B\n",
    "    row_index=topk_ind.diagonal(dim1=1,dim2=2)[:,col_index] # BxB\n",
    "    \n",
    "    #This should find the rows with the biggest gap in the cube and be in the form _,_,B\n",
    "    #print(col_index)\n",
    "    #print(row_index)\n",
    "    #I had expected to end in a one_hot matrix, but I think I'm going to end in a list of indices, and doing a .sum(-1) \n",
    "    return col_index,row_index\n",
    "\n",
    "def calculate_mask(shape:torch.Tensor,ros,cols,row_lookups,replaceval:torch.Tensor=torch.tensor(0)):\n",
    "    tensor=torch.ones_like(shape,dtype=torch.float)\n",
    "    tensor[ros]=torch.where(row_lookups[cols]>0,replaceval,row_lookups[cols])\n",
    "    tensor[:,cols]=replaceval\n",
    "    return tensor\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def lookup_sizes_vfast(sizes:torch.Tensor):\n",
    "    return torch.diag(torch.ones_like(sizes)).repeat_interleave(sizes,dim=0).repeat_interleave(sizes,dim=1).to(dtype=torch.long,device=sizes.device)\n",
    "\n",
    "\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,300,30))\n",
    "sizes=torch.tensor([5,4,3,4,5,4,5],device=Batched_TestTensor.device)\n",
    "start=time.time()\n",
    "outputs=original_method(Batched_TestTensor.clone().cpu(),sizes)\n",
    "\n",
    "x,y=zip(*outputs) #x is output idx, y is tgt idx\n",
    "\n",
    "src=torch.cat([torch.as_tensor(x) for x in x])\n",
    "tgt=torch.cat([torch.as_tensor(y) for y in y])\n",
    "end=time.time()-start\n",
    "print(\"original method took:\",end)\n",
    "print(outputs)\n",
    "fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "row_lookups=lookup_sizes_vfast(sizes)\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "    row_lookups=lookup_sizes_vfast(sizes)\n",
    "    outputs=Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    outputs=in_place_Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    outputs=no_for_loop_Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import reduce,partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Defining the user-defined cubes() function\n",
    "def square(logits):\n",
    "    #a function that takes numpy logits and plots them on an x and y axis\n",
    "    logits=logits.relu()\n",
    "\n",
    "    plt.figure(figsize=(logits.shape[0],logits.shape[1]))\n",
    "    plt.imshow(logits)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def cubes(logits):\n",
    "    # Defining the size of the axes\n",
    "    logits=torch.clamp(logits,min=-1,max=1)\n",
    "    x, y, z = np.indices(logits.shape)\n",
    "    sidex,sidey,sidez=logits.shape\n",
    "    # Defining the length of the sides of the cubes\n",
    "    cube = (x < sidex) & (y < sidey) & (z < sidez)\n",
    "    # Defining the shape of the figure to be a cube\n",
    "    voxelarray = cube\n",
    "    # Defining the colors for the cubes\n",
    "    colors = np.empty((3,*voxelarray.shape), dtype=float)\n",
    "    # Defining the color of the cube\n",
    "    c=np.sqrt(np.sqrt(logits.flatten()).unflatten(0,(sidex,sidey,sidez)).cpu().numpy())\n",
    "    #colors[cube] = c.astype(str)[cube]\n",
    "    colors= np.stack([c,c, c],axis=-1) #c,c,1-c\n",
    "    #print(colors.shape)\n",
    "    # Defining the axes and the figure object\n",
    "    ax = plt.figure(figsize=(9, 9)).add_subplot(projection='3d')\n",
    "    # Plotting the cube in the figure\n",
    "    ax.voxels(voxelarray , facecolors=colors, edgecolor='k')\n",
    "    # Defining the title of the graph\n",
    "    #plt.title(\"Batch MSE loss between random values and perfect case in n=3 dimensions\")\n",
    "    # Displaying the graph\n",
    "    plt.show()\n",
    "\n",
    "def hsquare(logits):\n",
    "    # Defining the size of the axes\n",
    "    logits=torch.clamp(logits,min=-1,max=1)\n",
    "\n",
    "    sidew,sidex,sidey,sidez=logits.shape\n",
    "    x,y = np.indices((sidew*sidex,sidey*sidez))\n",
    "    # Defining the length of the sides of the cubes\n",
    "    square = (x < (sidew*sidex)) & (y < (sidey*sidez))\n",
    "    # Defining the shape of the figure to be a cube\n",
    "    voxelarray = square\n",
    "    # Defining the colors for the cubes\n",
    "    colors = np.empty((*voxelarray.shape,3), dtype=int)\n",
    "    # Defining the color of the cube\n",
    "    #input is shape (B, B, B,B)\n",
    "    #C needs to be (b*b, B*b) \\\n",
    "    c=torch.softmax(logits.flatten(),dim=0).unflatten(0,(sidew*sidex,sidey*sidez)).cpu().numpy()\n",
    "    c=c/np.amax(c)\n",
    "\n",
    "    #c=np.sqrt(np.sqrt(smax(MLoss(sqsqlogits,pfsqsqlogits).flatten()).unflatten(0,(B*B,B*B)).cpu().numpy()))\n",
    "    colors= np.stack([c,c,c],axis=-1)\n",
    "    # Defining the axes and the figure object\n",
    "    ax = plt.imshow(colors[:, :, :])\n",
    "\n",
    "    # Plotting the cube in the figure\n",
    "    # Defining the title of the graph\n",
    "    #plt.title(\"Perfect case logits in n=4 dimensions plotted on a (B^2, B^2) \")\n",
    "    # Displaying the graph\n",
    "    plt.show()\n",
    "# Defining the main() function\n",
    "def hypcubes(side):\n",
    "    # Defining the size of the axes\n",
    "    u,v,w,x, y, z = np.indices((B,B,B,B, B, B))\n",
    "    # Defining the length of the sides of the cubes\n",
    "    cube =  (u < side) & (v < side) & (w < side)& (x < side) & (y < side) & (z < side)\n",
    "    # Defining the shape of the figure to be a cube\n",
    "    voxelarray = cube\n",
    "    # Defining the colors for the cubes\n",
    "    colors = np.empty(voxelarray.shape, dtype=object)\n",
    "    # Defining the color of the cube\n",
    "    c=np.sqrt(np.sqrt(torch.softmax(Blogits.flatten()).unflatten(0,(B,B,B,B,B,B)).cpu().numpy()))*2\n",
    "    colors[cube] = c.astype(str)[cube]\n",
    "    # Defining the axes and the figure object\n",
    "    ax = plt.figure(figsize=(9, 9)).add_subplot(projection='3d')\n",
    "    # Plotting the cube in the figure\n",
    "    ax.voxels(voxelarray , facecolors=colors, edgecolor='k')\n",
    "    # Defining the title of the graph\n",
    "    #plt.title(\"Batch MSE loss between random values and perfect case in n=3 dimensions\")\n",
    "    # Displaying the graph\n",
    "    plt.show()\n",
    "def draw(logits):\n",
    "    # Defining the side of the cube\n",
    "    sides = len(logits.shape) #(subtract to take slices)\n",
    "    # Calling the cubes () function\n",
    "    #cubes(sides)\n",
    "    if sides==2:\n",
    "      square(logits)\n",
    "    if sides==3:\n",
    "      cubes(logits)\n",
    "    if sides==4:\n",
    "      hsquare(logits)\n",
    "    if sides==6:\n",
    "      hypcubes(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 aten::repeat        23.07%       4.224ms        44.34%       8.117ms     122.985us       2.932ms        14.23%       8.380ms     126.970us           0 b           0 b       7.32 Mb           0 b            66  \n",
      "             aten::as_strided         0.08%      14.000us         0.08%      14.000us       0.022us       2.461ms        11.94%       2.461ms       3.950us           0 b           0 b           0 b           0 b           623  \n",
      "                    aten::max         9.78%       1.791ms        10.85%       1.987ms      31.047us       1.992ms         9.67%       2.598ms      40.594us           0 b           0 b     736.00 Kb     736.00 Kb            64  \n",
      "                  aten::copy_         3.05%     558.000us         6.24%       1.142ms       8.785us       1.417ms         6.88%       1.417ms      10.900us           0 b           0 b           0 b           0 b           130  \n",
      "                 aten::unfold         8.36%       1.530ms         8.37%       1.533ms       7.742us       1.390ms         6.75%       2.357ms      11.904us           0 b           0 b           0 b           0 b           198  \n",
      "                 aten::argmax         3.03%     555.000us         3.57%     653.000us      20.406us       1.022ms         4.96%       1.114ms      34.812us           0 b           0 b      16.00 Kb      16.00 Kb            32  \n",
      "                 aten::expand         5.66%       1.037ms         5.69%       1.041ms       7.886us     941.000us         4.57%       1.333ms      10.098us           0 b           0 b           0 b           0 b           132  \n",
      "              aten::unsqueeze         3.11%     569.000us         3.11%     570.000us       8.636us     900.000us         4.37%       1.090ms      16.515us           0 b           0 b           0 b           0 b            66  \n",
      "           aten::masked_fill_         4.14%     758.000us         7.75%       1.418ms      22.156us     858.000us         4.16%       1.469ms      22.953us           0 b           0 b           0 b           0 b            64  \n",
      "                  aten::empty         2.33%     427.000us         2.33%     427.000us       3.163us     751.000us         3.64%     751.000us       5.563us           8 b           8 b      14.59 Mb      14.59 Mb           135  \n",
      "            aten::masked_fill         5.78%       1.059ms        25.73%       4.710ms      73.594us     737.000us         3.58%       4.351ms      67.984us           0 b           0 b       7.27 Mb           0 b            64  \n",
      "                    aten::div         1.15%     210.000us         1.68%     308.000us       9.625us     713.000us         3.46%     713.000us      22.281us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                  aten::clone         5.47%       1.001ms        12.20%       2.233ms      34.891us     688.000us         3.34%       2.145ms      33.516us           0 b           0 b       7.27 Mb           0 b            64  \n",
      "                aten::permute         3.26%     597.000us         3.26%     597.000us       9.328us     543.000us         2.64%     740.000us      11.562us           0 b           0 b           0 b           0 b            64  \n",
      "                    aten::sub         0.99%     181.000us         1.44%     263.000us       8.219us     513.000us         2.49%     513.000us      16.031us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "             aten::empty_like         2.78%     509.000us         3.87%     708.000us      11.062us     455.000us         2.21%     803.000us      12.547us           0 b           0 b       7.27 Mb           0 b            64  \n",
      "              aten::expand_as         2.67%     489.000us         5.49%       1.006ms      15.242us     439.000us         2.13%       1.094ms      16.576us           0 b           0 b           0 b           0 b            66  \n",
      "                    aten::add         1.45%     266.000us         1.99%     365.000us      11.406us     438.000us         2.13%     438.000us      13.688us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                   aten::item         2.53%     464.000us         2.54%     465.000us       7.266us     436.000us         2.12%     611.000us       9.547us           0 b           0 b           0 b           0 b            64  \n",
      "                aten::numpy_T         2.71%     497.000us         5.98%       1.094ms      17.094us     392.000us         1.90%       1.132ms      17.688us           0 b           0 b           0 b           0 b            64  \n",
      "                  aten::alias         0.02%       3.000us         0.02%       3.000us       0.045us     190.000us         0.92%     190.000us       2.879us           0 b           0 b           0 b           0 b            66  \n",
      "    aten::_local_scalar_dense         0.01%       1.000us         0.01%       1.000us       0.016us     175.000us         0.85%     175.000us       2.734us           0 b           0 b           0 b           0 b            64  \n",
      "                  aten::fill_         0.14%      26.000us         0.28%      51.000us      12.750us      67.000us         0.33%      67.000us      16.750us           0 b           0 b           0 b           0 b             4  \n",
      "                 aten::arange         0.18%      33.000us         0.34%      63.000us      31.500us      33.000us         0.16%      70.000us      35.000us           0 b           0 b       1.00 Kb           0 b             2  \n",
      "                  aten::zeros         0.19%      35.000us         0.53%      97.000us      48.500us      27.000us         0.13%     105.000us      52.500us           0 b           0 b       2.00 Kb           0 b             2  \n",
      "         aten::fill_diagonal_         0.18%      33.000us         0.31%      57.000us      28.500us      26.000us         0.13%      63.000us      31.500us           0 b           0 b           0 b           0 b             2  \n",
      "                  aten::zero_         0.10%      19.000us         0.28%      51.000us      25.500us      17.000us         0.08%      59.000us      29.500us           0 b           0 b           0 b           0 b             2  \n",
      "                 aten::select         0.08%      14.000us         0.08%      15.000us      15.000us      13.000us         0.06%      18.000us      18.000us           0 b           0 b           0 b           0 b             1  \n",
      "                aten::detach_         0.08%      15.000us         0.09%      16.000us       8.000us      13.000us         0.06%      22.000us      11.000us           0 b           0 b           0 b           0 b             2  \n",
      "                      detach_         0.01%       1.000us         0.01%       1.000us       0.500us       9.000us         0.04%       9.000us       4.500us           0 b           0 b           0 b           0 b             2  \n",
      "                aten::resize_         0.02%       3.000us         0.02%       3.000us       3.000us       7.000us         0.03%       7.000us       7.000us           0 b           0 b         512 b         512 b             1  \n",
      "                     aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.03%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "             aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.03%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "                     [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us          -8 b          -8 b     -15.70 Mb     -15.70 Mb           451  \n",
      "             cudaLaunchKernel         5.73%       1.049ms         5.73%       1.049ms       3.208us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           327  \n",
      "              cudaMemcpyAsync         1.83%     335.000us         1.83%     335.000us       5.234us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "        cudaDeviceSynchronize         0.03%       5.000us         0.03%       5.000us       5.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 18.308ms\n",
      "Self CUDA time total: 20.607ms\n",
      "\n",
      "func recursive ACC : 17/30\n",
      "score: tensor(268.3737, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          aten::nonzero         9.73%       3.150ms        25.77%       8.343ms     130.359us       5.802ms        16.22%       8.081ms     126.266us           0 b           0 b      34.00 Kb       7.50 Kb            64  \n",
      "                                           aten::select         8.39%       2.715ms         8.39%       2.717ms       8.464us       2.984ms         8.34%       3.883ms      12.097us           0 b           0 b           0 b           0 b           321  \n",
      "                                       aten::as_strided         0.03%       9.000us         0.03%       9.000us       0.009us       2.904ms         8.12%       2.904ms       2.833us           0 b           0 b           0 b           0 b          1025  \n",
      "                                 aten::_index_put_impl_        10.75%       3.481ms        43.26%      14.002ms     218.781us       2.577ms         7.20%      13.419ms     209.672us           0 b           0 b       1.50 Kb     -32.50 Kb            64  \n",
      "                                           aten::repeat        11.04%       3.575ms        21.14%       6.843ms     106.922us       2.301ms         6.43%       7.553ms     118.016us           0 b           0 b     256.00 Kb           0 b            64  \n",
      "                                             aten::topk         4.00%       1.294ms         5.38%       1.741ms      27.203us       2.157ms         6.03%       2.157ms      33.703us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                        aten::unsqueeze         3.28%       1.062ms         3.28%       1.062ms       8.297us       1.838ms         5.14%       2.192ms      17.125us           0 b           0 b           0 b           0 b           128  \n",
      "                                           aten::expand         2.96%     958.000us         2.96%     958.000us       7.484us       1.305ms         3.65%       1.675ms      13.086us           0 b           0 b           0 b           0 b           128  \n",
      "                                         aten::scatter_         2.86%     926.000us         3.50%       1.132ms      17.688us       1.278ms         3.57%       1.450ms      22.656us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::copy_         1.21%     393.000us         1.98%     642.000us      10.031us       1.079ms         3.02%       1.079ms      16.859us           0 b           0 b           0 b           0 b            64  \n",
      "                                          aten::reshape         3.06%     992.000us         3.06%     992.000us       7.750us     945.000us         2.64%       1.302ms      10.172us           0 b           0 b           0 b           0 b           128  \n",
      "                                    aten::empty_strided         0.68%     219.000us         0.68%     219.000us       3.422us     918.000us         2.57%     918.000us      14.344us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                           aten::unfold         3.03%     982.000us         3.04%     984.000us       7.688us     915.000us         2.56%       1.272ms       9.938us           0 b           0 b           0 b           0 b           128  \n",
      "                                                aten::t         1.49%     481.000us         3.12%       1.009ms      15.766us     841.000us         2.35%       1.695ms      26.484us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::slice         2.81%     910.000us         2.81%     910.000us       9.479us     791.000us         2.21%       1.068ms      11.125us           0 b           0 b           0 b           0 b            96  \n",
      "                                       aten::zeros_like         3.01%     974.000us         8.27%       2.676ms      41.812us     692.000us         1.93%       3.073ms      48.016us           0 b           0 b      64.00 Kb           0 b            64  \n",
      "                                        aten::expand_as         1.48%     480.000us         2.95%     954.000us      14.906us     675.000us         1.89%       1.302ms      20.344us           0 b           0 b           0 b           0 b            64  \n",
      "                                        aten::transpose         1.62%     523.000us         1.63%     528.000us       8.250us     652.000us         1.82%     854.000us      13.344us           0 b           0 b           0 b           0 b            64  \n",
      "                                           aten::argmax         1.76%     571.000us         2.07%     670.000us      20.938us     579.000us         1.62%     671.000us      20.969us           0 b           0 b      16.00 Kb      16.00 Kb            32  \n",
      "                                            aten::fill_         0.66%     214.000us         1.26%     408.000us       6.375us     558.000us         1.56%     558.000us       8.719us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::index_put_         1.80%     582.000us        45.05%      14.584ms     227.875us     469.000us         1.31%      13.888ms     217.000us           0 b           0 b           0 b      -1.50 Kb            64  \n",
      "                                            aten::zero_         1.76%     569.000us         3.02%     977.000us      15.266us     465.000us         1.30%       1.023ms      15.984us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::empty_like         1.56%     506.000us         2.24%     725.000us      11.328us     440.000us         1.23%       1.358ms      21.219us           0 b           0 b      64.00 Kb           0 b            64  \n",
      "                                            aten::empty         0.66%     214.000us         0.66%     214.000us       3.194us     386.000us         1.08%     386.000us       5.761us           8 b           8 b     256.00 Kb     256.00 Kb            67  \n",
      "                                              aten::add         0.74%     238.000us         1.04%     338.000us      10.562us     367.000us         1.03%     367.000us      11.469us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us     357.000us         1.00%     357.000us       2.789us           0 b           0 b           0 b           0 b           128  \n",
      "                                          aten::resize_         0.43%     138.000us         0.43%     138.000us       2.123us     355.000us         0.99%     355.000us       5.462us           0 b           0 b      27.00 Kb      27.00 Kb            65  \n",
      "                                              aten::div         0.72%     234.000us         1.03%     333.000us      10.406us     341.000us         0.95%     341.000us      10.656us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                              aten::sub         0.59%     190.000us         0.86%     278.000us       8.688us     313.000us         0.87%     313.000us       9.781us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                             aten::set_         1.68%     544.000us         1.68%     544.000us       8.500us     234.000us         0.65%     234.000us       3.656us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::alias         0.00%       0.000us         0.00%       0.000us       0.000us     185.000us         0.52%     185.000us       2.891us           0 b           0 b           0 b           0 b            64  \n",
      "                                           aten::arange         0.10%      31.000us         0.18%      58.000us      29.000us      32.000us         0.09%      65.000us      32.500us           0 b           0 b       1.00 Kb           0 b             2  \n",
      "                                          aten::detach_         0.05%      17.000us         0.06%      18.000us       9.000us      18.000us         0.05%      25.000us      12.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.02%       7.000us       3.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                                detach_         0.00%       1.000us         0.00%       1.000us       0.500us       7.000us         0.02%       7.000us       3.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.02%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us          -8 b          -8 b    -784.50 Kb    -784.50 Kb           451  \n",
      "                                       cudaLaunchKernel         6.99%       2.264ms         6.99%       2.264ms       2.944us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           769  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.003us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           320  \n",
      "                                  cudaFuncGetAttributes         0.28%      90.000us         0.28%      90.000us       1.406us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.01%       2.000us         0.01%       2.000us       0.004us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           512  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           384  \n",
      "                                        cudaMemcpyAsync         8.55%       2.769ms         8.55%       2.769ms      43.266us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "                                  cudaStreamSynchronize         0.21%      67.000us         0.21%      67.000us       1.047us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "                                  cudaDeviceSynchronize         0.01%       4.000us         0.01%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 32.370ms\n",
      "Self CUDA time total: 35.773ms\n",
      "\n",
      "func recursive v2 \n",
      " ACC : 16/30\n",
      "score: tensor(267.2455, device='cuda:0')\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::argmax         9.40%       1.539ms        11.19%       1.831ms      19.073us       1.876ms         9.94%       2.158ms      22.479us           0 b           0 b      48.00 Kb      48.00 Kb            96  \n",
      "                                             aten::topk         7.09%       1.160ms         9.57%       1.566ms      24.469us       1.730ms         9.16%       1.730ms      27.031us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                              aten::max         3.93%     644.000us         5.19%     850.000us      13.281us       1.391ms         7.37%       1.391ms      21.734us           0 b           0 b      64.00 Kb      64.00 Kb            64  \n",
      "                                              aten::sub         3.92%     642.000us         5.55%     908.000us       9.458us       1.359ms         7.20%       1.359ms      14.156us           0 b           0 b     160.00 Kb     160.00 Kb            96  \n",
      "                                       aten::as_strided         0.07%      11.000us         0.07%      11.000us       0.029us       1.110ms         5.88%       1.110ms       2.883us           0 b           0 b           0 b           0 b           385  \n",
      "                                            aten::zero_         3.44%     563.000us         5.79%     948.000us      14.812us       1.065ms         5.64%       1.600ms      25.000us           0 b           0 b           0 b           0 b            64  \n",
      "                                        aten::unsqueeze         3.21%     526.000us         3.21%     526.000us       8.219us       1.025ms         5.43%       1.205ms      18.828us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::add         3.64%     596.000us         5.16%     845.000us       8.802us       1.023ms         5.42%       1.023ms      10.656us           0 b           0 b     384.00 Kb     384.00 Kb            96  \n",
      "                                            aten::slice         6.69%       1.095ms         6.73%       1.102ms       8.609us       1.005ms         5.32%       1.387ms      10.836us           0 b           0 b           0 b           0 b           128  \n",
      "                                             aten::diff         9.06%       1.483ms        25.80%       4.223ms      65.984us     980.000us         5.19%       4.024ms      62.875us           0 b           0 b      32.00 Kb           0 b            64  \n",
      "                                          aten::one_hot         9.11%       1.491ms        31.15%       5.099ms      79.672us     913.000us         4.84%       5.838ms      91.219us           0 b           0 b     480.00 Kb           0 b            64  \n",
      "                                         aten::scatter_         4.87%     798.000us         6.05%     991.000us      15.484us     905.000us         4.79%       1.078ms      16.844us           0 b           0 b           0 b           0 b            64  \n",
      "                                           aten::narrow         6.05%     990.000us        12.78%       2.092ms      16.344us     879.000us         4.66%       2.266ms      17.703us           0 b           0 b           0 b           0 b           128  \n",
      "                                              aten::mul         2.85%     466.000us         4.03%     660.000us      10.312us     823.000us         4.36%     823.000us      12.859us           0 b           0 b     256.00 Kb     256.00 Kb            64  \n",
      "                                              aten::div         1.23%     201.000us         1.81%     297.000us       9.281us     730.000us         3.87%     730.000us      22.812us           0 b           0 b     128.00 Kb     128.00 Kb            32  \n",
      "                                            aten::zeros         5.81%     951.000us        12.77%       2.091ms      32.672us     706.000us         3.74%       2.642ms      41.281us           0 b           0 b     480.00 Kb           0 b            64  \n",
      "                                            aten::fill_         1.22%     199.000us         2.35%     385.000us       6.016us     535.000us         2.83%     535.000us       8.359us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::empty         1.19%     194.000us         1.19%     194.000us       2.985us     337.000us         1.79%     337.000us       5.185us           0 b           0 b     480.00 Kb     480.00 Kb            65  \n",
      "                                          aten::permute         1.65%     270.000us         1.65%     270.000us       8.438us     248.000us         1.31%     334.000us      10.438us           0 b           0 b           0 b           0 b            32  \n",
      "                                          aten::numpy_T         1.41%     230.000us         3.05%     500.000us      15.625us     201.000us         1.06%     535.000us      16.719us           0 b           0 b           0 b           0 b            32  \n",
      "                                           aten::select         0.15%      24.000us         0.16%      27.000us      27.000us      24.000us         0.13%      31.000us      31.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                           aten::arange         0.18%      30.000us         0.36%      59.000us      29.500us      11.000us         0.06%      19.000us       9.500us           0 b           0 b       1.00 Kb           0 b             2  \n",
      "                                          aten::resize_         0.02%       3.000us         0.02%       3.000us       3.000us       1.000us         0.01%       1.000us       1.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                       cudaLaunchKernel        12.33%       2.018ms        12.33%       2.018ms       2.862us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           705  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      -1.55 Mb      -1.55 Mb           769  \n",
      "                                 cudaDeviceGetAttribute         0.01%       1.000us         0.01%       1.000us       0.004us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           256  \n",
      "                                  cudaFuncGetAttributes         0.42%      69.000us         0.42%      69.000us       1.078us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            64  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.02%       3.000us         0.02%       3.000us       0.006us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           512  \n",
      "                                  cudaDeviceSynchronize         1.06%     173.000us         1.06%     173.000us     173.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 16.370ms\n",
      "Self CUDA time total: 18.877ms\n",
      "\n",
      "func recursive v3 \n",
      " ACC : 17/30\n",
      "score: tensor(268.3737, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-29 20:59:40 90542:90542 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "def no_for_loop_triu_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "    remove=torch.ones_like(rewards,dtype=torch.bool).triu().unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights,dim=0).values\n",
    "    Locations=comb_fn(rewards,Costs)\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "def no_for_loop_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights,dim=0).values\n",
    "    #plt.show(plt.imshow(Costs.cpu().numpy()))\n",
    "    \n",
    "    Locations=comb_fn(rewards,Costs)\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "def no_for_loop_v2_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "\n",
    "    Costs=next_highest_fn(weights1,dim=1).values\n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "def no_for_loop_v2_triu_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "   \n",
    "    remove=torch.ones_like(rewards,dtype=torch.bool).tril().unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights1,dim=1).values \n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "def no_for_loop_v3_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "\n",
    "    Costs=next_highest_fn(weights1,dim=1).values\n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "def no_for_loop_v3_triu_MyLinearSumAssignment(rewards:torch.Tensor,maximize=False,tril=False):\n",
    "\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(0,torch.max,torch.sub,torch.argmax))[maximize]\n",
    "   \n",
    "    remove=torch.ones_like(rewards,dtype=torch.bool).tril().unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "    Costs=next_highest_fn(weights1,dim=1).values \n",
    "    Costs2=next_highest_fn(weights2,dim=0).values\n",
    "    Cost_total=Costs+Costs2\n",
    "    Locations=rewards - Cost_total/2\n",
    "    col_index=final_fn(Locations,dim=1)\n",
    "    return torch.arange(Locations.shape[0],device=Locations.device),col_index\n",
    "\n",
    "\n",
    "def reduceLinearSumAssignment(rewards:torch.Tensor,cost_neg:torch.Tensor,next_highest_fn: Callable,remove):\n",
    "    removehw,removehwT=remove\n",
    "    # rewards is HW, weights is  B(H) H W \n",
    "    weights=rewards.unsqueeze(0).repeat(*tuple([rewards.shape[0]]+ [1]*len(rewards.shape)))\n",
    "    #rewards is shape hw, weights is shape h w w\n",
    "    weights=weights.masked_fill(removehw,cost_neg)#.permute(1,2,0)\n",
    "    #draw(weights.cpu())\n",
    "    Costs=next_highest_fn(weights,dim=1).values #should not be 0  \n",
    "    #draw(Costs.cpu())\n",
    "    #print(Costs.shape)\n",
    "    weights2=rewards.T.unsqueeze(0).repeat(*tuple([rewards.shape[1]]+ [1]*len(rewards.shape)))\n",
    "\n",
    "    weights2=weights2.masked_fill(removehwT,cost_neg)#.permute(1,2,0)\n",
    "    Costs2=next_highest_fn(weights2,dim=1).values #should not be 0\n",
    "    #d#raw(Costs2.cpu())\n",
    "    #print(Costs2.shape)\n",
    "    Cost_total= torch.add(Costs,Costs2.T)\n",
    "    return Cost_total\n",
    "\n",
    "def reduceLinearSumAssignment_vm(rewards:torch.Tensor,cost_neg:torch.Tensor,next_highest_fn: Callable,remove:torch.Tensor):\n",
    "    weights=rewards.unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[-1]]))\n",
    "    weights1=weights.masked_fill(remove,cost_neg)#.permute(1,2,0)\n",
    "    weights2=weights.masked_fill(remove.permute(1,0,2),cost_neg)#.permute(1,2,0)\n",
    "    \n",
    "    Costs=next_highest_fn(weights1,dim=1).values #should not be 0  \n",
    "    Costs2=next_highest_fn(weights2,dim=0).values #should not be 0\n",
    "\n",
    "    #Cost_total=Costs+Costs2 # max,min or plus? min max seem to be worse than plus\n",
    "    Cost_total= torch.add(Costs,Costs2)\n",
    "    \n",
    "    return Cost_total\n",
    "def reduceLinearSumAssignment_v2(rewards:torch.Tensor,maximize=False):\n",
    "    Topv,topi=rewards.topk(k=2,dim=1,largest=maximize)\n",
    "    costs=Topv[:,0].unsqueeze(1).repeat(1,rewards.shape[-1])\n",
    "    #print(costs.shape)\n",
    "    one_hot=torch.zeros_like(rewards, dtype=torch.bool).scatter_(1,topi[:,0].unsqueeze(1),1)\n",
    "    #draw(one_hot.to(dtype=torch.float,device=\"cpu\"))\n",
    "    costs[one_hot]=Topv[:,1]\n",
    "    #draw(costs.cpu())\n",
    "    topv2,topi2=rewards.topk(k=2,dim=0,largest=maximize)\n",
    "    costs2=topv2[0].unsqueeze(0).repeat(rewards.shape[0],1)\n",
    "    one_hot2 = torch.zeros_like(rewards, dtype=torch.bool).scatter_(0, topi2[0].unsqueeze(0), 1)\n",
    "    costs2[one_hot2]=topv2[1]\n",
    "    #draw(costs2.cpu())\n",
    "    Cost_total= costs2+costs\n",
    "    #draw(Cost_total.cpu())\n",
    "\n",
    "    return Cost_total\n",
    "\n",
    "\n",
    "def reduceLinearSumAssignment_v3(rewards:torch.Tensor,maximize=False):\n",
    "\n",
    "    #30,32\n",
    "    TotalCosts= torch.max(rewards,dim=1,keepdim=True).values + torch.max(rewards,dim=0,keepdim=True).values\n",
    "    #30,32\n",
    "    diffs= torch.diff(rewards.topk(k=2,dim=1,largest=maximize).values,dim=1)\n",
    "    #30,1\n",
    "    diffs2= torch.diff(rewards.topk(k=2,dim=0,largest=maximize).values,dim=0)\n",
    "    #1,32\n",
    "    one_hot=torch.nn.functional.one_hot(torch.argmax(rewards,dim=1),num_classes=rewards.shape[1])\n",
    "    #30,32\n",
    "    one_hot=one_hot*diffs\n",
    "    #30,32\n",
    "    one_hot2=torch.nn.functional.one_hot(torch.argmax(rewards,dim=0),num_classes=rewards.shape[0])\n",
    "    #32,30\n",
    "\n",
    "    one_hot2=one_hot2.T * diffs2\n",
    "    deltas=one_hot+one_hot2\n",
    "    totalCosts=TotalCosts+deltas\n",
    "    return totalCosts\n",
    "\n",
    "\n",
    "def reduceLinearSumAssignment_v4(rewards:torch.Tensor,maximize=False):\n",
    "\n",
    "    #30,32\n",
    "    TotalCosts= torch.max(rewards,dim=1,keepdim=True).values + torch.max(rewards,dim=0,keepdim=True).values\n",
    "    #30,32\n",
    "    #diffs= torch.diff(rewards.topk(k=2,dim=1,largest=maximize).values,dim=1)\n",
    "    #30,1\n",
    "    diffs2= torch.diff(rewards.topk(k=2,dim=0,largest=maximize).values,dim=0)\n",
    "    #1,32\n",
    "    #one_hot=torch.nn.functional.one_hot(torch.argmax(rewards,dim=1),num_classes=rewards.shape[1])\n",
    "    #30,32\n",
    "    #one_hot=one_hot*diffs\n",
    "    #30,32\n",
    "    one_hot2=torch.nn.functional.one_hot(torch.argmax(rewards,dim=0),num_classes=rewards.shape[0])\n",
    "    #32,30\n",
    "\n",
    "    one_hot2=one_hot2.T * diffs2\n",
    "    #deltas=one_hot+one_hot2\n",
    "    totalCosts=TotalCosts+one_hot2#deltas\n",
    "    return totalCosts\n",
    "\n",
    "def recursiveLinearSumAssignment(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((torch.tensor(float('inf')),torch.min,torch.add,torch.argmin),(torch.tensor(float('-inf')),torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #we need to make a mask that holds the diagonal of a H x H matrix repeated B times, and then one with the diagonal of a BxB matrix repeated H times\n",
    "\n",
    "    removeHHB=torch.zeros((rewards.shape[0],rewards.shape[0]),dtype=torch.bool,device=rewards.device).fill_diagonal_(1).unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape) + [rewards.shape[1]]))\n",
    "    removeBBH=torch.zeros((rewards.shape[1],rewards.shape[1]),dtype=torch.bool,device=rewards.device).fill_diagonal_(1).unsqueeze(-1).repeat(*tuple([1]*len(rewards.shape)+[rewards.shape[0]]))\n",
    "    y_values=[]\n",
    "    #rewards=rewards-  (rewards.min())\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost=reduceLinearSumAssignment(rewards,cost_neg,next_highest_fn,(removeHHB,removeBBH))\n",
    "        rewards=rewards - cost/factor\n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index, y_values\n",
    "\n",
    "def recursiveLinearSumAssignment_v2(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((torch.tensor(float('inf')),torch.min,torch.add,torch.argmin),(torch.tensor(float('-inf')),torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    # remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost2=reduceLinearSumAssignment_v2(rewards,maximize=maximize)\n",
    "        rewards=rewards- (cost2/factor)# can remove\n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #return torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index, y_values\n",
    "\n",
    "def recursiveLinearSumAssignment_v3(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    final_fn=torch.argmax if maximize else torch.argmin\n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost=reduceLinearSumAssignment_v3(rewards,maximize=maximize)\n",
    "        rewards=rewards-(cost/factor)# can remove\n",
    "        #draw(rewards.cpu())\n",
    "        #? why is this suggested??? rewards,_,_=torch.svd(rewards)\n",
    "        #rewards=rewards ** (rewards-cost/factor) #times here makes it very spiky! \n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index,y_values\n",
    "\n",
    "def recursiveLinearSumAssignment_v4(rewards:torch.Tensor,maximize=False,factor=1):\n",
    "    final_fn=torch.argmax if maximize else torch.argmin\n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "        cost=reduceLinearSumAssignment_v3(rewards,maximize=maximize)\n",
    "        rewards=rewards-(cost/factor)# can remove\n",
    "        #draw(rewards.cpu())\n",
    "        #? why is this suggested??? rewards,_,_=torch.svd(rewards)\n",
    "        #rewards=rewards ** (rewards-cost/factor) #times here makes it very spiky! \n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index,y_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def recursiveLinearSumAssignment_reductionComparison(rewards:torch.Tensor,maximize=False,factor=0.1):\n",
    "    cost_neg,next_highest_fn,comb_fn,final_fn=((torch.tensor(float('inf')),torch.min,torch.add,torch.argmin),(torch.tensor(float('-inf')),torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    #cost_neg,next_highest_fn,comb_fn,final_fn=((1e9,torch.min,torch.add,torch.argmin),(-1e9,torch.max,torch.sub,torch.argmax))[maximize] \n",
    "    remove=torch.zeros_like(rewards,dtype=torch.bool).fill_diagonal_(1).unsqueeze(0).repeat(*tuple([rewards.shape[-1]]+[1]*len(rewards.shape)))\n",
    "    y_values=[]\n",
    "    for i in range(rewards.shape[-1]):\n",
    "\n",
    "        cost=reduceLinearSumAssignment(rewards,cost_neg,next_highest_fn,remove)\n",
    "        cost2=reduceLinearSumAssignment_v2(rewards,maximize=maximize)\n",
    "        cost3=reduceLinearSumAssignment_v3(rewards,maximize=maximize)\n",
    "        draw(cost3.cpu())\n",
    "        draw(cost2.cpu())\n",
    "        draw(cost.cpu())\n",
    "        print(\"Cost- v2\",torch.mean(torch.abs(cost-cost2)))\n",
    "        print(\"cost- v3\",torch.mean(torch.abs(cost-cost3)))\n",
    "        print(\"2 v 3\",torch.mean(torch.abs(cost2-cost3)))\n",
    "        rewards=rewards- (cost2/factor)# can remove\n",
    "    \n",
    "        col_index=final_fn(rewards,dim=1)\n",
    "        #x,y=torch.arange(rewards.shape[0],device=rewards.device),col_index\n",
    "        y_values.append(col_index)\n",
    "    \n",
    "    return torch.arange(rewards.shape[0],device=rewards.device),col_index, y_values\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#try linear sum assignment\n",
    "import time\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,30,32)).cuda()\n",
    "Batched_TestTensor=Batched_TestTensor*10\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, record_shapes=True, with_flops=True, profile_memory=True) as prof: \n",
    "    X,Y=linear_sum_assignment(Batched_TestTensor[0].cpu().numpy(), maximize=True)\n",
    "    \n",
    "# print(\"scipy took:\")\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "# print(\"score:\",Batched_TestTensor[0][X,Y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x,y,_=recursiveLinearSumAssignment(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} ACC : {}/{}\".format(\"recursive\",torch.sum(y.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x,y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x1,y1,_=recursiveLinearSumAssignment_v2(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v2\",torch.sum(y1.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x1,y1].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x2,y2,_=recursiveLinearSumAssignment_v3(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v3\",torch.sum(y2.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x2,y2].sum())\n",
    "\n",
    "\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, profile_memory=True) as prof: \n",
    "    x2,y2,_=recursiveLinearSumAssignment_v4(Batched_TestTensor[0],maximize=True,factor=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v3\",torch.sum(y2.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x2,y2].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#try linear sum assignment\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m Batched_TestTensor\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mrand((\u001b[39m8\u001b[39m,\u001b[39m30\u001b[39m,\u001b[39m30\u001b[39m))\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m Batched_TestTensor\u001b[39m=\u001b[39mBatched_TestTensor\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-gpu-03/home/user/Pair-DETR-PTL/LinearSumAssignment.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile() \u001b[39mas\u001b[39;00m prof:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#try linear sum assignment\n",
    "import time\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,30,30)).cuda()\n",
    "Batched_TestTensor=Batched_TestTensor*10\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    X,Y=linear_sum_assignment(Batched_TestTensor[0].cpu().numpy(), maximize=True)\n",
    "    \n",
    "print(\"scipy took:\")\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"score:\",Batched_TestTensor[0][X,Y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    x,y,_=recursiveLinearSumAssignment(Batched_TestTensor[0],maximize=True)\n",
    "draw((torch.stack(_,dim=0).cpu()==torch.as_tensor(Y)).int().to(dtype=torch.float,device=\"cpu\"))\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} ACC : {}/{}\".format(\"recursive\",torch.sum(y.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x,y].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof: \n",
    "    x1,y1,_=recursiveLinearSumAssignment_v2(Batched_TestTensor[0],maximize=True)\n",
    "draw((torch.stack(_,dim=0).cpu()==torch.as_tensor(Y)).int().to(dtype=torch.float,device=\"cpu\"))\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v2\",torch.sum(y1.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x1,y1].sum())\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof: \n",
    "    x1,y1,_=recursiveLinearSumAssignment_v3(Batched_TestTensor[0],maximize=True)\n",
    "draw((torch.stack(_,dim=0).cpu()==torch.as_tensor(Y)).int().to(dtype=torch.float,device=\"cpu\"))\n",
    "# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(\"func {} \\n ACC : {}/{}\".format(\"recursive v3\",torch.sum(y1.cpu()==torch.as_tensor(Y)),len(Y)))\n",
    "print(\"score:\",Batched_TestTensor[0][x1,y1].sum())\n",
    "for factor in np.arange(0.2,3,0.1):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.abs(torch.rand((30,30)))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "  \n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "x_axis=\"Number of times the steps\"\n",
    "y_axis=\"Fraction of correct assignments\"\n",
    "plt.xlabel(x_axis)\n",
    "plt.ylabel(y_axis)\n",
    "\n",
    "title=\"A Graph showing mean accuracy based on cost matrix\"\n",
    "plt.title(title)  \n",
    "plt.show()\n",
    "for factor in np.arange(0.2,3,0.2):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.rand((30,30))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment_v2(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "    title=\"A Graph showing mean accuracy based on multiplying by costs, factor:{}\".format(\"0.2 - 3 in steps of 0.1\")\n",
    "    plt.title(title)\n",
    "    #x axis is the number of times the algorithm was run\n",
    "    #y axis is the accuracy\n",
    "    x_axis=\"Number of times the steps\"\n",
    "    y_axis=\"Fraction of correct assignments\"\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "\n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for factor in np.arange(0.2,3,0.1):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.rand((30,30))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment_v3(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "    title=\"A Graph showing mean accuracy based on multiplying by costs, factor:{}\".format(\"0.2 - 3 in steps of 0.1\")\n",
    "    plt.title(title)\n",
    "    #x axis is the number of times the algorithm was run\n",
    "    #y axis is the accuracy\n",
    "    x_axis=\"Number of times the steps\"\n",
    "    y_axis=\"Fraction of correct assignments\"\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "\n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for factor in np.arange(0.2,3,0.1):\n",
    "    y_values=torch.zeros((30,30))\n",
    "\n",
    "    for i in range(100):\n",
    "        Batched_TestTensor=torch.rand((30,30))\n",
    "        X,Y=linear_sum_assignment(Batched_TestTensor.cpu().numpy(), maximize=True)\n",
    "        x,y,y_val=recursiveLinearSumAssignment_v4(Batched_TestTensor,maximize=True,factor=factor)\n",
    "        y_values=y_values+ (torch.stack(y_val,dim=0).cpu()==torch.as_tensor(Y)).int()\n",
    "    title=\"A Graph showing mean accuracy based on multiplying by costs, factor:{}\".format(\"0.2 - 3 in steps of 0.1\")\n",
    "    plt.title(title)\n",
    "    #x axis is the number of times the algorithm was run\n",
    "    #y axis is the accuracy\n",
    "    x_axis=\"Number of times the steps\"\n",
    "    y_axis=\"Fraction of correct assignments\"\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "\n",
    "    plt.plot(torch.mean(y_values,dim=1)/100,label=\"factor:{}\".format(factor))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#try linear sum assignment\n",
    "import time\n",
    "start=time.time()\n",
    "X,Y=linear_sum_assignment(Batched_TestTensor[0].cpu().numpy(), maximize=False)\n",
    "end=time.time()-start\n",
    "print(\"scipy took:\",end)\n",
    "print(\"score:\",Batched_TestTensor[0][X,Y].sum())\n",
    "trial_functions=[no_for_loop_MyLinearSumAssignment,\n",
    "                 no_for_loop_triu_MyLinearSumAssignment,\n",
    "                 no_for_loop_v2_MyLinearSumAssignment,\n",
    "                 no_for_loop_v2_triu_MyLinearSumAssignment,\n",
    "                 no_for_loop_v3_MyLinearSumAssignment,\n",
    "                 no_for_loop_v3_triu_MyLinearSumAssignment]\n",
    "for func in trial_functions:\n",
    "    warmup,_=func(Batched_TestTensor[0])\n",
    "    start=time.time()\n",
    "    x,y=func(Batched_TestTensor[0],maximize=False)\n",
    "    end=time.time()-start\n",
    "    print(\"func {} \\n TOOK {}, \\n ACC : {}/{}\".format(func,end,torch.sum(y==torch.as_tensor(Y)),len(Y)))\n",
    "    print(\"score:\",Batched_TestTensor[0][x,y].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to construct some nn.modules instead of this heavy set of calls and for loops\n",
    "for the Batch_Linear sum assignment method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-19 18:58:11 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::resolve_conj         0.01%       1.000us         0.01%       1.000us       1.000us             1  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.40%      33.000us         9.79%     811.000us      12.477us            65  \n",
      "                                         aten::_to_copy         1.15%      95.000us         9.40%     778.000us      25.097us            31  \n",
      "                                    aten::empty_strided         1.16%      96.000us         1.16%      96.000us       3.000us            32  \n",
      "                                            aten::copy_         6.36%     527.000us        10.58%     876.000us      14.129us            62  \n",
      "                                        cudaMemcpyAsync        16.61%       1.375ms        16.61%       1.375ms       5.612us           245  \n",
      "                                  cudaStreamSynchronize         3.61%     299.000us         3.61%     299.000us       1.220us           245  \n",
      "                                 aten::split_with_sizes         0.17%      14.000us         0.18%      15.000us      15.000us             1  \n",
      "                                       aten::as_strided         0.08%       7.000us         0.08%       7.000us       0.016us           439  \n",
      "                                           aten::select         4.24%     351.000us         4.31%     357.000us       1.630us           219  \n",
      "                                              aten::cat         0.21%      17.000us         0.33%      27.000us      27.000us             1  \n",
      "                                       cudaLaunchKernel        12.28%       1.017ms        12.28%       1.017ms       3.198us           318  \n",
      "                                        aten::ones_like         0.04%       3.000us         0.23%      19.000us      19.000us             1  \n",
      "                                       aten::empty_like         0.02%       2.000us         0.07%       6.000us       6.000us             1  \n",
      "                                            aten::fill_         2.42%     200.000us         3.70%     306.000us       9.000us            34  \n",
      "                                             aten::diag         0.04%       3.000us         0.46%      38.000us      38.000us             1  \n",
      "                                       aten::diag_embed         0.07%       6.000us         0.42%      35.000us      35.000us             1  \n",
      "                                            aten::zeros         0.08%       7.000us         0.35%      29.000us      14.500us             2  \n",
      "                                            aten::empty         0.95%      79.000us         0.95%      79.000us       2.135us            37  \n",
      "                                            aten::zero_         0.06%       5.000us         0.19%      16.000us       8.000us             2  \n",
      "                                         aten::diagonal         0.02%       2.000us         0.02%       2.000us       2.000us             1  \n",
      "                                aten::repeat_interleave         0.43%      36.000us         5.01%     415.000us     103.750us             4  \n",
      "                                           aten::cumsum         0.43%      36.000us         0.58%      48.000us      24.000us             2  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us             8  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.01%       1.000us         0.01%       1.000us       0.004us           242  \n",
      "                                 cudaDeviceGetAttribute         0.00%       0.000us         0.00%       0.000us       0.000us           122  \n",
      "                                             aten::item         4.84%     401.000us        23.16%       1.918ms       8.963us           214  \n",
      "                              aten::_local_scalar_dense         5.68%     470.000us        21.68%       1.795ms       8.388us           214  \n",
      "                                               aten::ge         0.22%      18.000us         0.29%      24.000us      12.000us             2  \n",
      "                                              aten::all         0.23%      19.000us         0.31%      26.000us      13.000us             2  \n",
      "                                     aten::index_select         0.22%      18.000us         0.40%      33.000us      16.500us             2  \n",
      "                                          aten::resize_         0.77%      64.000us         0.77%      64.000us       2.000us            32  \n",
      "                                             aten::ones         0.05%       4.000us         0.19%      16.000us      16.000us             1  \n",
      "                                              aten::mul         2.75%     228.000us         4.06%     336.000us      11.200us            30  \n",
      "                                            aten::clamp         2.58%     214.000us         3.68%     305.000us      10.167us            30  \n",
      "                                             aten::topk         7.00%     580.000us         9.65%     799.000us      26.633us            30  \n",
      "                                  cudaFuncGetAttributes         0.60%      50.000us         0.60%      50.000us       1.667us            30  \n",
      "                                             aten::diff         1.27%     105.000us         7.50%     621.000us      20.700us            30  \n",
      "                                           aten::narrow         1.07%      89.000us         2.26%     187.000us       3.117us            60  \n",
      "                                            aten::slice         2.84%     235.000us         2.84%     235.000us       1.958us           120  \n",
      "                                              aten::sub         2.68%     222.000us         3.79%     314.000us      10.467us            30  \n",
      "                                              aten::abs         3.09%     256.000us         9.42%     780.000us      13.000us            60  \n",
      "                                           aten::argmax         3.99%     330.000us         5.86%     485.000us      16.167us            30  \n",
      "                                          aten::reshape         1.16%      96.000us         1.16%      96.000us       1.600us            60  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us            60  \n",
      "                                           aten::argmin         3.73%     309.000us         4.92%     407.000us      13.567us            30  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us            90  \n",
      "                                       aten::index_put_         0.65%      54.000us        12.37%       1.024ms      34.133us            30  \n",
      "                                 aten::_index_put_impl_         3.70%     306.000us        11.71%     970.000us      32.333us            30  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 8.280ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 18:58:12 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 18:58:12 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::resolve_conj         0.00%       1.000us         0.00%       1.000us       1.000us             1  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.32%     239.000us         7.26%       5.430ms       9.020us           602  \n",
      "                                         aten::_to_copy         1.39%       1.040ms         6.78%       5.071ms      16.847us           301  \n",
      "                                    aten::empty_strided         1.22%     914.000us         1.22%     914.000us       3.037us           301  \n",
      "                                            aten::copy_         3.50%       2.620ms         7.98%       5.971ms       9.935us           601  \n",
      "                                        cudaMemcpyAsync        17.22%      12.886ms        17.22%      12.886ms       5.367us          2401  \n",
      "                                  cudaStreamSynchronize         3.87%       2.899ms         3.87%       2.899ms       1.207us          2401  \n",
      "                                 aten::split_with_sizes         0.02%      18.000us         0.03%      21.000us      21.000us             1  \n",
      "                                       aten::as_strided         0.01%       4.000us         0.01%       4.000us       0.001us          4214  \n",
      "                                           aten::select         4.52%       3.379ms         4.52%       3.379ms       1.604us          2107  \n",
      "                                              aten::cat         0.04%      31.000us         0.07%      49.000us      49.000us             1  \n",
      "                                       cudaLaunchKernel        12.67%       9.477ms        12.67%       9.477ms       3.156us          3003  \n",
      "                                             aten::ones         0.01%       7.000us         0.03%      25.000us      25.000us             1  \n",
      "                                            aten::empty         0.82%     611.000us         0.82%     611.000us       2.023us           302  \n",
      "                                            aten::fill_         2.44%       1.824ms         3.67%       2.749ms       9.103us           302  \n",
      "                                            aten::zeros         0.01%       4.000us         0.02%      16.000us      16.000us             1  \n",
      "                                            aten::zero_         0.00%       2.000us         0.01%       9.000us       9.000us             1  \n",
      "                                              aten::add         2.83%       2.118ms         4.43%       3.314ms      11.047us           300  \n",
      "                                            aten::clamp         2.82%       2.110ms         4.03%       3.012ms      10.040us           300  \n",
      "                                             aten::topk         7.84%       5.867ms        10.50%       7.860ms      26.200us           300  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.001us          1200  \n",
      "                                  cudaFuncGetAttributes         0.50%     372.000us         0.50%     372.000us       1.240us           300  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%       1.000us         0.00%       1.000us       0.000us          2400  \n",
      "                                             aten::diff         1.18%     880.000us         7.89%       5.901ms      19.670us           300  \n",
      "                                           aten::narrow         1.23%     918.000us         2.44%       1.826ms       3.043us           600  \n",
      "                                            aten::slice         2.87%       2.146ms         2.87%       2.146ms       1.788us          1200  \n",
      "                                              aten::sub         2.84%       2.126ms         4.05%       3.028ms      10.093us           300  \n",
      "                                              aten::abs         3.30%       2.470ms        10.17%       7.606ms      12.677us           600  \n",
      "                                          aten::resize_         0.80%     602.000us         0.80%     602.000us       2.007us           300  \n",
      "                                           aten::argmax         8.21%       6.146ms        11.46%       8.577ms      14.295us           600  \n",
      "                                          aten::reshape         1.27%     948.000us         1.27%     952.000us       1.587us           600  \n",
      "                                   aten::_reshape_alias         0.01%       4.000us         0.01%       4.000us       0.007us           600  \n",
      "                                             aten::item         5.11%       3.823ms        24.51%      18.341ms       8.734us          2100  \n",
      "                              aten::_local_scalar_dense         6.33%       4.737ms        22.91%      17.141ms       8.162us          2100  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us           900  \n",
      "                                       aten::index_put_         0.86%     640.000us        13.41%      10.034ms      33.447us           300  \n",
      "                                 aten::_index_put_impl_         3.95%       2.957ms        12.81%       9.587ms      31.957us           300  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 74.822ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 18:58:13 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 18:58:13 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 18:58:13 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::resolve_conj         0.00%       1.000us         0.00%       1.000us       1.000us             1  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               aten::to         0.28%     190.000us         7.73%       5.339ms       8.825us           605  \n",
      "                                         aten::_to_copy         1.61%       1.113ms         7.22%       4.988ms      16.571us           301  \n",
      "                                    aten::empty_strided         1.34%     924.000us         1.34%     924.000us       3.060us           302  \n",
      "                                            aten::copy_         3.69%       2.547ms         8.54%       5.894ms       9.791us           602  \n",
      "                                        cudaMemcpyAsync        18.23%      12.587ms        18.23%      12.587ms       5.234us          2405  \n",
      "                                  cudaStreamSynchronize         3.74%       2.580ms         3.74%       2.580ms       1.073us          2405  \n",
      "                                 aten::split_with_sizes         0.03%      19.000us         0.03%      23.000us      23.000us             1  \n",
      "                                       aten::as_strided         0.02%      12.000us         0.02%      12.000us       0.003us          3919  \n",
      "                                           aten::select         4.57%       3.156ms         4.58%       3.163ms       1.313us          2409  \n",
      "                                              aten::cat         0.04%      30.000us         0.07%      50.000us      50.000us             1  \n",
      "                                       cudaLaunchKernel        12.43%       8.585ms        12.43%       8.585ms       3.159us          2718  \n",
      "                                        aten::ones_like         0.01%       5.000us         0.04%      27.000us      27.000us             1  \n",
      "                                       aten::empty_like         0.00%       2.000us         0.01%       8.000us       8.000us             1  \n",
      "                                            aten::fill_         2.98%       2.056ms         4.38%       3.025ms       9.951us           304  \n",
      "                                             aten::diag         0.07%      46.000us         0.07%      46.000us      46.000us             1  \n",
      "                                       aten::diag_embed         0.01%       9.000us         0.06%      44.000us      44.000us             1  \n",
      "                                            aten::zeros         0.01%       8.000us         0.04%      31.000us      15.500us             2  \n",
      "                                            aten::empty         0.90%     624.000us         0.90%     624.000us       2.033us           307  \n",
      "                                            aten::zero_         0.01%       4.000us         0.02%      16.000us       8.000us             2  \n",
      "                                         aten::diagonal         0.00%       2.000us         0.00%       2.000us       2.000us             1  \n",
      "                                aten::repeat_interleave         0.05%      37.000us         0.71%     492.000us     123.000us             4  \n",
      "                                           aten::cumsum         0.06%      41.000us         0.08%      58.000us      29.000us             2  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us             8  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%       2.000us         0.00%       2.000us       0.001us          2402  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.000us         0.00%       1.000us       0.001us          1202  \n",
      "                                             aten::item         4.26%       2.943ms        26.02%      17.968ms       8.540us          2104  \n",
      "                              aten::_local_scalar_dense         6.86%       4.739ms        23.91%      16.512ms       7.848us          2104  \n",
      "                                               aten::ge         0.03%      24.000us         0.05%      32.000us      16.000us             2  \n",
      "                                              aten::all         0.03%      24.000us         0.04%      30.000us      15.000us             2  \n",
      "                                     aten::index_select         0.03%      22.000us         0.06%      39.000us      19.500us             2  \n",
      "                                          aten::resize_         0.88%     609.000us         0.88%     609.000us       2.017us           302  \n",
      "                                             aten::ones         0.01%       5.000us         0.02%      17.000us      17.000us             1  \n",
      "                                              aten::add         3.09%       2.132ms         4.79%       3.306ms      11.020us           300  \n",
      "                                            aten::clamp         3.06%       2.113ms         4.37%       3.017ms      10.057us           300  \n",
      "                                             aten::topk         8.31%       5.738ms        11.04%       7.626ms      25.420us           300  \n",
      "                                  cudaFuncGetAttributes         0.47%     323.000us         0.47%     323.000us       1.077us           300  \n",
      "                                             aten::diff         1.13%     782.000us         8.42%       5.816ms      19.387us           300  \n",
      "                                           aten::narrow         1.28%     882.000us         2.64%       1.820ms       3.033us           600  \n",
      "                                            aten::slice         2.52%       1.741ms         2.52%       1.741ms       1.934us           900  \n",
      "                                              aten::sub         3.05%       2.108ms         4.36%       3.011ms      10.037us           300  \n",
      "                                              aten::abs         3.55%       2.448ms        10.93%       7.547ms      12.578us           600  \n",
      "                                           aten::argmax         4.52%       3.121ms         6.70%       4.628ms      15.427us           300  \n",
      "                                          aten::reshape         1.34%     922.000us         1.34%     922.000us       1.537us           600  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us           600  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us           900  \n",
      "                                       aten::index_put_         1.27%     880.000us        14.43%       9.963ms      33.210us           300  \n",
      "                                 aten::_index_put_impl_         4.22%       2.913ms        13.67%       9.439ms      31.463us           300  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 69.050ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Batch_MyLinearSumAssignment(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    mask=torch.ones(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    finder,replaceval=(torch.argmax,0) if maximize else (torch.argmin,float(1e9))\n",
    "    for _ in range(row_lookups.shape[0]): # number of columns\n",
    "        deltas=torch.diff(torch.topk(torch.clamp(Batched_TruthTensor*mask,max=100),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0])) \n",
    "        row_index=finder(Batched_TruthTensor[:,col_index],dim=0) # BxB\n",
    "        mask[:,col_index]=replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=replaceval\n",
    "        results[row_index,col_index]=1\n",
    "    return results\n",
    "\n",
    "def Batch_MyLinearSumAssignment_v2(Batched_TruthTensor:torch.Tensor,row_lookups:torch.Tensor, maximize=False,lookahead=2):\n",
    "    mask=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device, dtype=torch.bool)\n",
    "    results=torch.zeros(Batched_TruthTensor.shape,device=Batched_TruthTensor.device)\n",
    "    finder=(torch.argmax) if maximize else (torch.argmin)#\n",
    "    Batched_TruthTensor=Batched_TruthTensor.sub(Batched_TruthTensor.min())\n",
    "    replaceval=torch.min(Batched_TruthTensor) if maximize else torch.max(Batched_TruthTensor)+1\n",
    "    for _ in range(row_lookups.shape[0]): # number of columns\n",
    "        deltas=torch.diff(torch.topk(torch.where(mask,replaceval,Batched_TruthTensor),lookahead,dim=0,largest=maximize).values,n=lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0])) \n",
    "        row_index=finder(Batched_TruthTensor[:,col_index],dim=0) # BxB\n",
    "        mask[:,col_index]=True \n",
    "        mask[row_index,row_lookups[col_index]]=True\n",
    "        results[row_index,col_index]=1\n",
    "    return results\n",
    "# We have 2 methods, taking the row and col index via hooks\n",
    "# we can generate the row col index with argmax or use the original sort method.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "\n",
    "class LinearSumAssignmentModule(nn.Module):\n",
    "    def __init__(self,maximize=True,version=2):\n",
    "        super(LinearSumAssignmentModule,self).__init__()\n",
    "        self.lookahead=2\n",
    "        self.finder,self.replaceval=(torch.argmax,float('-inf')) if maximize else (torch.argmin,float('inf'))\n",
    "        self.topk=partial(torch.topk,largest=maximize)\n",
    "        self.do_step=self.do_step_v2 if version==2 else self.do_step_v1\n",
    "    def do_step_v1(self,C,mask,results,row_lookups):\n",
    "        col_topks_v,col_topks_i=self.topk(torch.clamp(C+mask,max=100),self.lookahead,dim=0)\n",
    "        deltas=torch.diff(col_topks_v,n=self.lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0]))\n",
    "        row_index=col_topks_i[0][col_index]\n",
    "        mask[:,col_index]=self.replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=self.replaceval\n",
    "        results[row_index,col_index]=1\n",
    "        return C,mask,results\n",
    "    \n",
    "    def do_step_v2(self,C,mask,results,row_lookups):\n",
    "        col_topks_v,col_topks_i=self.topk(torch.clamp(C+mask,max=100),self.lookahead,dim=0)\n",
    "        deltas=torch.diff(col_topks_v,n=self.lookahead-1,dim=0)\n",
    "        col_index=torch.argmax(torch.abs(deltas[0]))\n",
    "        row_index=self.finder(C[:,col_index],dim=0)\n",
    "        mask[:,col_index]=self.replaceval \n",
    "        mask[row_index,row_lookups[col_index]]=self.replaceval\n",
    "        results[row_index,col_index]=1\n",
    "        return C,mask,results\n",
    "    def forward(self,C:torch.Tensor,row_lookups:torch.Tensor):\n",
    "        mask=torch.ones(C.shape,device=C.device)\n",
    "        results=torch.zeros(C.shape,device=C.device)\n",
    "        for _ in range(C.shape[0]):\n",
    "            C,mask,results=self.do_step(C,mask,results,row_lookups)\n",
    "        return results\n",
    "    \n",
    "\n",
    "#comparison\n",
    "my_module=LinearSumAssignmentModule(maximize=True,version=2).cuda()\n",
    "my_module2=LinearSumAssignmentModule(maximize=True,version=1).cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def lookup_sizes_vfast(sizes:torch.Tensor):\n",
    "    return torch.diag(torch.ones_like(sizes)).repeat_interleave(sizes,dim=0).repeat_interleave(sizes,dim=1).to(dtype=torch.long,device=sizes.device)\n",
    "\n",
    "\n",
    "\n",
    "Batched_TestTensor=torch.rand((8,300,30)).cuda()\n",
    "sizes=torch.tensor([5,4,3,4,5,4,5],device=Batched_TestTensor.device)\n",
    "\n",
    "fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "row_lookups=lookup_sizes_vfast(sizes)\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1).to(device=\"cuda\")\n",
    "    row_lookups=lookup_sizes_vfast(sizes)\n",
    "    outputs=Batch_MyLinearSumAssignment(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1).to(device=\"cuda\")\n",
    "\n",
    "    outputs=my_module(fx,row_lookups=row_lookups)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1).to(device=\"cuda\")\n",
    "\n",
    "    outputs=my_module2(fx,row_lookups=lookup_sizes_vfast(sizes))\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          aten::nonzero         7.78%      59.000us        15.17%     115.000us     115.000us      84.000us        10.82%     117.000us     117.000us           0 b           0 b       8.50 Kb           0 b             1  \n",
      "                                aten::repeat_interleave        12.66%      96.000us        73.09%     554.000us     277.000us      79.000us        10.18%     562.000us     281.000us           0 b           0 b      22.00 Kb      -6.00 Kb             2  \n",
      "                                            aten::index         9.37%      71.000us        30.08%     228.000us     228.000us      66.000us         8.51%     235.000us     235.000us           0 b           0 b     839.50 Kb     831.00 Kb             1  \n",
      "                                            aten::fill_         2.24%      17.000us         5.01%      38.000us      19.000us      46.000us         5.93%      46.000us      23.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::cumsum         4.49%      34.000us         6.07%      46.000us      46.000us      46.000us         5.93%      49.000us      49.000us           0 b           0 b         512 b         512 b             1  \n",
      "                              aten::_local_scalar_dense         0.79%       6.000us         4.49%      34.000us      17.000us      39.000us         5.03%      39.000us      19.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                     aten::index_select         4.09%      31.000us         5.54%      42.000us      42.000us      34.000us         4.38%      45.000us      45.000us           0 b           0 b      17.50 Kb           0 b             1  \n",
      "                                              aten::all         3.43%      26.000us         4.09%      31.000us      31.000us      32.000us         4.12%      35.000us      35.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                       aten::as_strided         0.79%       6.000us         0.79%       6.000us       0.750us      31.000us         3.99%      31.000us       3.875us           0 b           0 b           0 b           0 b             8  \n",
      "                                           aten::select         3.83%      29.000us         3.83%      29.000us       9.667us      30.000us         3.87%      39.000us      13.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                               aten::ge         2.51%      19.000us         3.17%      24.000us      24.000us      27.000us         3.48%      27.000us      27.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                       aten::diag_embed         3.83%      29.000us        13.19%     100.000us     100.000us      23.000us         2.96%     103.000us     103.000us           0 b           0 b       1.50 Kb           0 b             1  \n",
      "                                    aten::empty_strided         2.24%      17.000us         2.24%      17.000us      17.000us      22.000us         2.84%      22.000us      22.000us           0 b           0 b         512 b         512 b             1  \n",
      "                                            aten::copy_         1.72%      13.000us         2.37%      18.000us      18.000us      22.000us         2.84%      22.000us      22.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                          aten::permute         2.77%      21.000us         3.43%      26.000us      26.000us      21.000us         2.71%      30.000us      30.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::empty         1.45%      11.000us         1.45%      11.000us       3.667us      21.000us         2.71%      21.000us       7.000us           0 b           0 b       6.00 Kb       6.00 Kb             3  \n",
      "                                          aten::reshape         2.77%      21.000us         2.77%      21.000us      10.500us      19.000us         2.45%      27.000us      13.500us           0 b           0 b           0 b           0 b             2  \n",
      "                                        aten::ones_like         2.51%      19.000us        10.82%      82.000us      82.000us      16.000us         2.06%      86.000us      86.000us           0 b           0 b         512 b           0 b             1  \n",
      "                                            aten::zeros         2.51%      19.000us         5.54%      42.000us      42.000us      15.000us         1.93%      45.000us      45.000us           0 b           0 b       1.50 Kb           0 b             1  \n",
      "                                             aten::item         2.11%      16.000us         6.60%      50.000us      25.000us      15.000us         1.93%      54.000us      27.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                       aten::empty_like         1.98%      15.000us         4.22%      32.000us      32.000us      13.000us         1.68%      35.000us      35.000us           0 b           0 b         512 b           0 b             1  \n",
      "                                          aten::resize_         0.79%       6.000us         0.79%       6.000us       3.000us      12.000us         1.55%      12.000us       6.000us           0 b           0 b      26.00 Kb      26.00 Kb             2  \n",
      "                                         aten::diagonal         1.45%      11.000us         1.45%      11.000us      11.000us      10.000us         1.29%      13.000us      13.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::diag         1.19%       9.000us        14.38%     109.000us     109.000us       9.000us         1.16%     112.000us     112.000us           0 b           0 b       1.50 Kb           0 b             1  \n",
      "                                            aten::zero_         1.32%      10.000us         2.24%      17.000us      17.000us       9.000us         1.16%      20.000us      20.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                                aten::t         1.19%       9.000us         2.51%      19.000us      19.000us       9.000us         1.16%      22.000us      22.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                        aten::transpose         1.19%       9.000us         1.32%      10.000us      10.000us       9.000us         1.16%      13.000us      13.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                   aten::_reshape_alias         0.00%       0.000us         0.00%       0.000us       0.000us       8.000us         1.03%       8.000us       4.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::set_         1.58%      12.000us         1.58%      12.000us      12.000us       6.000us         0.77%       6.000us       6.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         0.39%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cudaLaunchKernel         9.63%      73.000us         9.63%      73.000us       4.867us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            15  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b   -1005.50 Kb   -1005.50 Kb             4  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.40%       3.000us         0.40%       3.000us       1.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                 cudaDeviceGetAttribute         0.13%       1.000us         0.13%       1.000us       0.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                        cudaMemcpyAsync         4.22%      32.000us         4.22%      32.000us      10.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                  cudaStreamSynchronize         0.53%       4.000us         0.53%       4.000us       1.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                  cudaDeviceSynchronize         0.53%       4.000us         0.53%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 758.000us\n",
      "Self CUDA time total: 776.000us\n",
      "\n",
      "torch.Size([537, 400])\n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              aten::select        42.76%     301.000us        42.76%     301.000us       9.121us     298.000us        35.73%     411.000us      12.455us           0 b           0 b           0 b           0 b            33  \n",
      "          aten::as_strided         0.28%       2.000us         0.28%       2.000us       0.030us     220.000us        26.38%     220.000us       3.333us           0 b           0 b           0 b           0 b            66  \n",
      "    aten::split_with_sizes        40.91%     288.000us        41.19%     290.000us     290.000us     187.000us        22.42%     294.000us     294.000us           0 b           0 b           0 b           0 b             1  \n",
      "                 aten::cat         3.41%      24.000us         4.83%      34.000us      34.000us      42.000us         5.04%      42.000us      42.000us           0 b           0 b     839.50 Kb     839.50 Kb             1  \n",
      "               aten::copy_         1.42%      10.000us         3.84%      27.000us      27.000us      31.000us         3.72%      31.000us      31.000us           0 b           0 b           0 b           0 b             1  \n",
      "            aten::_to_copy         4.26%      30.000us         9.09%      64.000us      64.000us      25.000us         3.00%      68.000us      68.000us         264 b           0 b           0 b           0 b             1  \n",
      "                  aten::to         1.70%      12.000us        10.80%      76.000us      76.000us      12.000us         1.44%      80.000us      80.000us         264 b           0 b           0 b           0 b             1  \n",
      "       aten::empty_strided         0.99%       7.000us         0.99%       7.000us       7.000us      12.000us         1.44%      12.000us      12.000us         264 b         264 b           0 b           0 b             1  \n",
      "        aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.48%       4.000us       4.000us           0 b           0 b           0 b           0 b             1  \n",
      "         aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         0.36%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "           cudaMemcpyAsync         2.13%      15.000us         2.13%      15.000us      15.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "     cudaStreamSynchronize         0.28%       2.000us         0.28%       2.000us       2.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                  [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us        -264 b        -264 b    -986.00 Kb    -986.00 Kb             2  \n",
      "          cudaLaunchKernel         1.42%      10.000us         1.42%      10.000us      10.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "     cudaDeviceSynchronize         0.43%       3.000us         0.43%       3.000us       3.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 704.000us\n",
      "Self CUDA time total: 834.000us\n",
      "\n",
      "torch.Size([400, 537])\n",
      "tensor(True, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-09-19 22:05:14 27074:27074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_ints=33\n",
    "ints=torch.randint(0,40,(num_ints,)).to(\"cuda\")\n",
    "sum_of_ints=ints.sum()\n",
    "Batched_TestTensor=torch.rand((num_ints,400,sum_of_ints)).cuda()\n",
    "sizes=ints\n",
    "\n",
    "\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True, record_shapes=True, with_flops=True, profile_memory=True) as prof: \n",
    "    fx2=Batched_TestTensor.permute(0,2,1)[torch.diag(torch.ones_like(sizes,dtype=torch.bool)).repeat_interleave(sizes,dim=1)]\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(fx2.shape)\n",
    "with torch.autograd.profiler.profile(use_cuda=True, record_shapes=True, with_flops=True, profile_memory=True) as prof: \n",
    "    fx=torch.cat([c[i] for i,c in enumerate(Batched_TestTensor.split(sizes.tolist(), -1))],dim=1)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "print(fx.shape)\n",
    "\n",
    "\n",
    "check=fx2==fx.T\n",
    "print(check.all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
